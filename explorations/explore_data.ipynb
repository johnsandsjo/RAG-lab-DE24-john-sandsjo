{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572afbab",
   "metadata": {},
   "source": [
    "# Explore the data in vectore db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d77cba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceDBConnection(uri='/Users/john.sandsjo/Documents/github/RAG-lab-DE24-john-sandsjo/transcript_repo')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "from pathlib import Path\n",
    "\n",
    "VECTOR_DB_PATH = Path.cwd().parent / \"transcript_repo\"\n",
    "vector_db = lancedb.connect(uri= VECTOR_DB_PATH)\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d4c3ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transcriptions']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a16f3df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(name='transcriptions', version=83, _conn=LanceDBConnection(uri='/Users/john.sandsjo/Documents/github/RAG-lab-DE24-john-sandsjo/transcript_repo'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"transcriptions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff325473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_link</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fastapi crud app</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Fastapi CRUD app\\n\\n**Kokchun Giang:** [00:0...</td>\n",
       "      <td>[-0.012556567, -0.01593715, 0.022671303, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - set theor...</td>\n",
       "      <td>[-0.027204884, -0.023552606, 0.019531347, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python fundamentals</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Python fundamentals\\n\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.011976539, 0.0025688808, 0.015519834, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>packaging in python</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Packaging in python\\n\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.0150246415, 0.0042777252, 0.038052212, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pydantic fundamentals</td>\n",
       "      <td>https://www.youtube.com/watch?v=hHCMUc3gv40</td>\n",
       "      <td># Pydantic fundamentals\\n\\n[00:00:00] Hello an...</td>\n",
       "      <td>[-0.017777685, -0.01204192, 0.02006065, -0.059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sql analytics course with duckdb - joins with ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=RjPen0FavwU</td>\n",
       "      <td># SQL analytics course with DuckDB - joins wit...</td>\n",
       "      <td>[-0.022949534, -0.022863599, 0.013395227, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pydantic with gemini to structure output in a ...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Pydantic with gemini to structure output in ...</td>\n",
       "      <td>[-0.01512796, -0.003907627, 0.015176425, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># pydanticAI chatbot\\n\\n[00:00:00] Hello and w...</td>\n",
       "      <td>[-0.012143856, -0.001205422, 0.013563879, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sql analytics course with duckdb - joins concepts</td>\n",
       "      <td>https://www.youtube.com/watch?v=LcI6GvmpuYA</td>\n",
       "      <td># SQL analytics course with DuckDB - joins con...</td>\n",
       "      <td>[-0.027722066, -0.016966412, 0.012043696, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>docker setup windows</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># docker setup windows\\n\\n[00:00:00] Hello and...</td>\n",
       "      <td>[-0.0034482135, 0.010729573, 0.016939094, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - Sakila BI...</td>\n",
       "      <td>[0.0055291746, -0.004573792, 0.019058505, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sql analytics course with duckdb - setup duckdb</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - setup duc...</td>\n",
       "      <td>[-0.008761382, -0.0034869136, 0.01760935, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sql analytics course with duckdb - strings con...</td>\n",
       "      <td>https://www.youtube.com/watch?v=F9I7aM4k9ug</td>\n",
       "      <td># SQL analytics course with DuckDB - strings c...</td>\n",
       "      <td>[-0.02525857, -0.011639317, 0.004399808, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>logistic regression theory</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Logistic regression theory\\n\\n[00:00:00] Hel...</td>\n",
       "      <td>[-0.008146983, -0.00016716555, 0.011266027, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>api trafiklab (1)</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># API trafiklab\\n\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.006812348, -0.0044766036, 0.014319714, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - pandas an...</td>\n",
       "      <td>[-0.009578243, -0.011996515, 0.012965736, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sql analytics course with duckdb - views tutorial</td>\n",
       "      <td>https://www.youtube.com/watch?v=v2k6ZZz23oc</td>\n",
       "      <td># SQL analytics course with DuckDB - views tut...</td>\n",
       "      <td>[-0.027096331, -0.0073001576, 0.0048975083, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pandas_read_excel</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># pandas\\_read\\_excel\\n\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.0038475876, 0.0054737586, 0.024301918, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>python intro</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># python intro\\n\\n[00:00:00] Hello and welcome...</td>\n",
       "      <td>[-0.0110368235, -0.0020397531, 0.012955041, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pytest unit testing</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># pytest unit testing\\n\\n[00:00:00] Hello and ...</td>\n",
       "      <td>[-0.014343338, 0.0007622975, 0.030120881, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sql analytics course with duckdb - sakila bi d...</td>\n",
       "      <td>https://www.youtube.com/watch?v=8jMIRtGwReY</td>\n",
       "      <td># SQL analytics course with DuckDB - Sakila BI...</td>\n",
       "      <td>[0.0055291746, -0.004573792, 0.019058505, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data platform course structure</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Data platform course structure\\n\\n[00:00:00]...</td>\n",
       "      <td>[0.010435624, -0.0016020014, 0.011163727, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>course structure for azure two weeks course</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Course structure for Azure two weeks course\\...</td>\n",
       "      <td>[0.0015313567, 0.012794174, 0.016358217, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>modern data stack - dockerize your data pipeline</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Modern data stack - dockerize your data pipe...</td>\n",
       "      <td>[0.0027987233, 0.014228618, 0.027441906, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xgboost hands on tutorial for classification</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># XGBoost hands on tutorial for classification...</td>\n",
       "      <td>[-0.004887973, 0.008207077, 0.013008361, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data storytelling</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># data storytelling\\n\\n[00:00:00] Hello and we...</td>\n",
       "      <td>[-0.011316549, 0.016874935, 0.012392512, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>api trafiklab</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># API trafiklab\\n\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[-0.006812348, -0.0044766036, 0.014319714, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sql analytics course with duckdb - course stru...</td>\n",
       "      <td>https://www.youtube.com/watch?v=weC950i58Gs</td>\n",
       "      <td># SQL analytics course with DuckDB - course st...</td>\n",
       "      <td>[0.0023245383, -0.0029253534, 0.0036489798, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fastapi and scikit-learn api connect to stream...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># FastAPI and scikit-learn API connect to stre...</td>\n",
       "      <td>[-0.017560659, 0.009985835, 0.01749353, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sql analytics course with duckdb - crud operat...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - CRUD oper...</td>\n",
       "      <td>[-0.018357037, -0.0009783215, 0.025988214, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sql analytics course with duckdb - pandas and ...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - pandas an...</td>\n",
       "      <td>[-0.009578243, -0.011996515, 0.012965736, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># PydanticAI fundamentals - outputting structu...</td>\n",
       "      <td>[-0.033087507, 0.0036856267, 0.02514256, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chat with your excel data - xlwings lite (1)</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Chat with your excel data - xlwings lite\\n\\n...</td>\n",
       "      <td>[-0.0071265996, 0.020476552, 0.017235534, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dbt modeling snowflake</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># dbt modeling snowflake\\n\\n**Kokchun Giang:**...</td>\n",
       "      <td>[-0.010636117, 0.01212832, 0.029030465, -0.086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Serving PydanticAI Gemini Model with FastAPI...</td>\n",
       "      <td>[-0.018388461, -0.006911759, 0.015190295, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>postgres sink</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># postgres sink\\n\\n[00:00:00] Hello and welcom...</td>\n",
       "      <td>[0.007228276, 0.021961471, 0.031665433, -0.088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>python_oop_1</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Python\\_oop\\_1\\n\\n**kokchun:** [00:00:00] He...</td>\n",
       "      <td>[-0.008043373, -0.011165032, 0.031197485, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>chat with your excel data - xlwings lite</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Chat with your excel data - xlwings lite\\n\\n...</td>\n",
       "      <td>[-0.0071265996, 0.020476552, 0.017235534, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>an introduction to the vector database lancedb</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># An introduction to the vector database Lance...</td>\n",
       "      <td>[-0.038686633, 0.0036908067, 0.02178414, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>serving pydanticai gemini model with fastapi t...</td>\n",
       "      <td>https://www.youtube.com/watch?v=mp650k5T2T8</td>\n",
       "      <td># Serving PydanticAI Gemini Model with FastAPI...</td>\n",
       "      <td>[-0.018388461, -0.006911759, 0.015190295, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>terraform setup</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Terraform setup\\n\\n[00:00:00] Hello and welc...</td>\n",
       "      <td>[-0.004057311, 0.01868715, 0.01563467, -0.0808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sql analytics with duckdb - introduction</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics with DuckDB - introduction\\n\\n...</td>\n",
       "      <td>[-0.028552804, -0.0118231885, 0.00639494, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sql analytics course with duckdb - set theory ...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - set theor...</td>\n",
       "      <td>[-0.027204884, -0.023552606, 0.019531347, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data processing course  structure</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># data processing course structure\\n\\n**Kokchu...</td>\n",
       "      <td>[0.0032914313, 0.01059015, 0.009196502, -0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>modern data stack - deploy dockerized dashboar...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Modern data stack - deploy dockerized dashbo...</td>\n",
       "      <td>[-0.0075815883, 0.02116889, 0.027429571, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sql analytics course with duckdb - subquery tu...</td>\n",
       "      <td>https://www.youtube.com/watch?v=aZQtKjWfaDw</td>\n",
       "      <td># SQL analytics course with DuckDB - subquery ...</td>\n",
       "      <td>[-0.012517108, -0.014230472, -0.0019505646, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>logistic regression hands on with scikit learn</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Logistic regression hands on with scikit lea...</td>\n",
       "      <td>[-0.0066825696, 0.002244388, 0.011106265, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sql analytics course with duckdb - dlt to load...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - dlt to lo...</td>\n",
       "      <td>[-0.0066205882, -0.0075128363, 0.019882608, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>modern data stack - using dlt to extract and l...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Modern data stack - using dlt to extract and...</td>\n",
       "      <td>[-0.00826649, 0.019363934, 0.016988434, -0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>hands on regularization</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Hands on regularization\\n\\n[00:00:00] Hello ...</td>\n",
       "      <td>[-0.009709013, 6.357031e-05, 0.023912106, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>azure static web app deploy react app</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># Azure static web app deploy react app\\n\\n[00...</td>\n",
       "      <td>[-0.012295628, 0.015832268, 0.025340993, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>how does llm work_</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># How does LLM work?\\n\\n[00:00:00] Hello and w...</td>\n",
       "      <td>[-0.027908303, 0.017137818, 0.023856219, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sql analytics course with duckdb - strings tut...</td>\n",
       "      <td>https://www.youtube.com/@AIgineer</td>\n",
       "      <td># SQL analytics course with DuckDB - strings t...</td>\n",
       "      <td>[-0.021185221, -0.0025146175, 0.01119325, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_title  \\\n",
       "0                                    fastapi crud app   \n",
       "1   sql analytics course with duckdb - set theory ...   \n",
       "2                                 python fundamentals   \n",
       "3                                 packaging in python   \n",
       "4                               pydantic fundamentals   \n",
       "5   sql analytics course with duckdb - joins with ...   \n",
       "6   pydantic with gemini to structure output in a ...   \n",
       "7                                  pydanticai chatbot   \n",
       "8   sql analytics course with duckdb - joins concepts   \n",
       "9                                docker setup windows   \n",
       "10  sql analytics course with duckdb - sakila bi d...   \n",
       "11    sql analytics course with duckdb - setup duckdb   \n",
       "12  sql analytics course with duckdb - strings con...   \n",
       "13                         logistic regression theory   \n",
       "14                                  api trafiklab (1)   \n",
       "15  sql analytics course with duckdb - pandas and ...   \n",
       "16  sql analytics course with duckdb - views tutorial   \n",
       "17                                  pandas_read_excel   \n",
       "18                                       python intro   \n",
       "19                                pytest unit testing   \n",
       "20  sql analytics course with duckdb - sakila bi d...   \n",
       "21                     data platform course structure   \n",
       "22        course structure for azure two weeks course   \n",
       "23   modern data stack - dockerize your data pipeline   \n",
       "24       xgboost hands on tutorial for classification   \n",
       "25                                  data storytelling   \n",
       "26                                      api trafiklab   \n",
       "27  sql analytics course with duckdb - course stru...   \n",
       "28  fastapi and scikit-learn api connect to stream...   \n",
       "29  sql analytics course with duckdb - crud operat...   \n",
       "30  sql analytics course with duckdb - pandas and ...   \n",
       "31  pydanticai fundamentals - outputting structure...   \n",
       "32       chat with your excel data - xlwings lite (1)   \n",
       "33                             dbt modeling snowflake   \n",
       "34  serving pydanticai gemini model with fastapi t...   \n",
       "35                                      postgres sink   \n",
       "36                                       python_oop_1   \n",
       "37           chat with your excel data - xlwings lite   \n",
       "38     an introduction to the vector database lancedb   \n",
       "39  serving pydanticai gemini model with fastapi t...   \n",
       "40                                    terraform setup   \n",
       "41           sql analytics with duckdb - introduction   \n",
       "42  sql analytics course with duckdb - set theory ...   \n",
       "43                  data processing course  structure   \n",
       "44  modern data stack - deploy dockerized dashboar...   \n",
       "45  sql analytics course with duckdb - subquery tu...   \n",
       "46     logistic regression hands on with scikit learn   \n",
       "47  sql analytics course with duckdb - dlt to load...   \n",
       "48  modern data stack - using dlt to extract and l...   \n",
       "49                            hands on regularization   \n",
       "50              azure static web app deploy react app   \n",
       "51                                 how does llm work_   \n",
       "52  sql analytics course with duckdb - strings tut...   \n",
       "\n",
       "                                     video_link  \\\n",
       "0             https://www.youtube.com/@AIgineer   \n",
       "1             https://www.youtube.com/@AIgineer   \n",
       "2             https://www.youtube.com/@AIgineer   \n",
       "3             https://www.youtube.com/@AIgineer   \n",
       "4   https://www.youtube.com/watch?v=hHCMUc3gv40   \n",
       "5   https://www.youtube.com/watch?v=RjPen0FavwU   \n",
       "6             https://www.youtube.com/@AIgineer   \n",
       "7             https://www.youtube.com/@AIgineer   \n",
       "8   https://www.youtube.com/watch?v=LcI6GvmpuYA   \n",
       "9             https://www.youtube.com/@AIgineer   \n",
       "10            https://www.youtube.com/@AIgineer   \n",
       "11            https://www.youtube.com/@AIgineer   \n",
       "12  https://www.youtube.com/watch?v=F9I7aM4k9ug   \n",
       "13            https://www.youtube.com/@AIgineer   \n",
       "14            https://www.youtube.com/@AIgineer   \n",
       "15            https://www.youtube.com/@AIgineer   \n",
       "16  https://www.youtube.com/watch?v=v2k6ZZz23oc   \n",
       "17            https://www.youtube.com/@AIgineer   \n",
       "18            https://www.youtube.com/@AIgineer   \n",
       "19            https://www.youtube.com/@AIgineer   \n",
       "20  https://www.youtube.com/watch?v=8jMIRtGwReY   \n",
       "21            https://www.youtube.com/@AIgineer   \n",
       "22            https://www.youtube.com/@AIgineer   \n",
       "23            https://www.youtube.com/@AIgineer   \n",
       "24            https://www.youtube.com/@AIgineer   \n",
       "25            https://www.youtube.com/@AIgineer   \n",
       "26            https://www.youtube.com/@AIgineer   \n",
       "27  https://www.youtube.com/watch?v=weC950i58Gs   \n",
       "28            https://www.youtube.com/@AIgineer   \n",
       "29            https://www.youtube.com/@AIgineer   \n",
       "30            https://www.youtube.com/@AIgineer   \n",
       "31            https://www.youtube.com/@AIgineer   \n",
       "32            https://www.youtube.com/@AIgineer   \n",
       "33            https://www.youtube.com/@AIgineer   \n",
       "34            https://www.youtube.com/@AIgineer   \n",
       "35            https://www.youtube.com/@AIgineer   \n",
       "36            https://www.youtube.com/@AIgineer   \n",
       "37            https://www.youtube.com/@AIgineer   \n",
       "38            https://www.youtube.com/@AIgineer   \n",
       "39  https://www.youtube.com/watch?v=mp650k5T2T8   \n",
       "40            https://www.youtube.com/@AIgineer   \n",
       "41            https://www.youtube.com/@AIgineer   \n",
       "42            https://www.youtube.com/@AIgineer   \n",
       "43            https://www.youtube.com/@AIgineer   \n",
       "44            https://www.youtube.com/@AIgineer   \n",
       "45  https://www.youtube.com/watch?v=aZQtKjWfaDw   \n",
       "46            https://www.youtube.com/@AIgineer   \n",
       "47            https://www.youtube.com/@AIgineer   \n",
       "48            https://www.youtube.com/@AIgineer   \n",
       "49            https://www.youtube.com/@AIgineer   \n",
       "50            https://www.youtube.com/@AIgineer   \n",
       "51            https://www.youtube.com/@AIgineer   \n",
       "52            https://www.youtube.com/@AIgineer   \n",
       "\n",
       "                                              content  \\\n",
       "0   # Fastapi CRUD app\\n\\n**Kokchun Giang:** [00:0...   \n",
       "1   # SQL analytics course with DuckDB - set theor...   \n",
       "2   # Python fundamentals\\n\\n[00:00:00] Hello and ...   \n",
       "3   # Packaging in python\\n\\n[00:00:00] Hello and ...   \n",
       "4   # Pydantic fundamentals\\n\\n[00:00:00] Hello an...   \n",
       "5   # SQL analytics course with DuckDB - joins wit...   \n",
       "6   # Pydantic with gemini to structure output in ...   \n",
       "7   # pydanticAI chatbot\\n\\n[00:00:00] Hello and w...   \n",
       "8   # SQL analytics course with DuckDB - joins con...   \n",
       "9   # docker setup windows\\n\\n[00:00:00] Hello and...   \n",
       "10  # SQL analytics course with DuckDB - Sakila BI...   \n",
       "11  # SQL analytics course with DuckDB - setup duc...   \n",
       "12  # SQL analytics course with DuckDB - strings c...   \n",
       "13  # Logistic regression theory\\n\\n[00:00:00] Hel...   \n",
       "14  # API trafiklab\\n\\n[00:00:00] Hello and welcom...   \n",
       "15  # SQL analytics course with DuckDB - pandas an...   \n",
       "16  # SQL analytics course with DuckDB - views tut...   \n",
       "17  # pandas\\_read\\_excel\\n\\n[00:00:00] Hello and ...   \n",
       "18  # python intro\\n\\n[00:00:00] Hello and welcome...   \n",
       "19  # pytest unit testing\\n\\n[00:00:00] Hello and ...   \n",
       "20  # SQL analytics course with DuckDB - Sakila BI...   \n",
       "21  # Data platform course structure\\n\\n[00:00:00]...   \n",
       "22  # Course structure for Azure two weeks course\\...   \n",
       "23  # Modern data stack - dockerize your data pipe...   \n",
       "24  # XGBoost hands on tutorial for classification...   \n",
       "25  # data storytelling\\n\\n[00:00:00] Hello and we...   \n",
       "26  # API trafiklab\\n\\n[00:00:00] Hello and welcom...   \n",
       "27  # SQL analytics course with DuckDB - course st...   \n",
       "28  # FastAPI and scikit-learn API connect to stre...   \n",
       "29  # SQL analytics course with DuckDB - CRUD oper...   \n",
       "30  # SQL analytics course with DuckDB - pandas an...   \n",
       "31  # PydanticAI fundamentals - outputting structu...   \n",
       "32  # Chat with your excel data - xlwings lite\\n\\n...   \n",
       "33  # dbt modeling snowflake\\n\\n**Kokchun Giang:**...   \n",
       "34  # Serving PydanticAI Gemini Model with FastAPI...   \n",
       "35  # postgres sink\\n\\n[00:00:00] Hello and welcom...   \n",
       "36  # Python\\_oop\\_1\\n\\n**kokchun:** [00:00:00] He...   \n",
       "37  # Chat with your excel data - xlwings lite\\n\\n...   \n",
       "38  # An introduction to the vector database Lance...   \n",
       "39  # Serving PydanticAI Gemini Model with FastAPI...   \n",
       "40  # Terraform setup\\n\\n[00:00:00] Hello and welc...   \n",
       "41  # SQL analytics with DuckDB - introduction\\n\\n...   \n",
       "42  # SQL analytics course with DuckDB - set theor...   \n",
       "43  # data processing course structure\\n\\n**Kokchu...   \n",
       "44  # Modern data stack - deploy dockerized dashbo...   \n",
       "45  # SQL analytics course with DuckDB - subquery ...   \n",
       "46  # Logistic regression hands on with scikit lea...   \n",
       "47  # SQL analytics course with DuckDB - dlt to lo...   \n",
       "48  # Modern data stack - using dlt to extract and...   \n",
       "49  # Hands on regularization\\n\\n[00:00:00] Hello ...   \n",
       "50  # Azure static web app deploy react app\\n\\n[00...   \n",
       "51  # How does LLM work?\\n\\n[00:00:00] Hello and w...   \n",
       "52  # SQL analytics course with DuckDB - strings t...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.012556567, -0.01593715, 0.022671303, -0.07...  \n",
       "1   [-0.027204884, -0.023552606, 0.019531347, -0.0...  \n",
       "2   [-0.011976539, 0.0025688808, 0.015519834, -0.0...  \n",
       "3   [-0.0150246415, 0.0042777252, 0.038052212, -0....  \n",
       "4   [-0.017777685, -0.01204192, 0.02006065, -0.059...  \n",
       "5   [-0.022949534, -0.022863599, 0.013395227, -0.0...  \n",
       "6   [-0.01512796, -0.003907627, 0.015176425, -0.07...  \n",
       "7   [-0.012143856, -0.001205422, 0.013563879, -0.0...  \n",
       "8   [-0.027722066, -0.016966412, 0.012043696, -0.0...  \n",
       "9   [-0.0034482135, 0.010729573, 0.016939094, -0.0...  \n",
       "10  [0.0055291746, -0.004573792, 0.019058505, -0.0...  \n",
       "11  [-0.008761382, -0.0034869136, 0.01760935, -0.0...  \n",
       "12  [-0.02525857, -0.011639317, 0.004399808, -0.07...  \n",
       "13  [-0.008146983, -0.00016716555, 0.011266027, -0...  \n",
       "14  [-0.006812348, -0.0044766036, 0.014319714, -0....  \n",
       "15  [-0.009578243, -0.011996515, 0.012965736, -0.0...  \n",
       "16  [-0.027096331, -0.0073001576, 0.0048975083, -0...  \n",
       "17  [-0.0038475876, 0.0054737586, 0.024301918, -0....  \n",
       "18  [-0.0110368235, -0.0020397531, 0.012955041, -0...  \n",
       "19  [-0.014343338, 0.0007622975, 0.030120881, -0.0...  \n",
       "20  [0.0055291746, -0.004573792, 0.019058505, -0.0...  \n",
       "21  [0.010435624, -0.0016020014, 0.011163727, -0.0...  \n",
       "22  [0.0015313567, 0.012794174, 0.016358217, -0.07...  \n",
       "23  [0.0027987233, 0.014228618, 0.027441906, -0.09...  \n",
       "24  [-0.004887973, 0.008207077, 0.013008361, -0.09...  \n",
       "25  [-0.011316549, 0.016874935, 0.012392512, -0.08...  \n",
       "26  [-0.006812348, -0.0044766036, 0.014319714, -0....  \n",
       "27  [0.0023245383, -0.0029253534, 0.0036489798, -0...  \n",
       "28  [-0.017560659, 0.009985835, 0.01749353, -0.085...  \n",
       "29  [-0.018357037, -0.0009783215, 0.025988214, -0....  \n",
       "30  [-0.009578243, -0.011996515, 0.012965736, -0.0...  \n",
       "31  [-0.033087507, 0.0036856267, 0.02514256, -0.07...  \n",
       "32  [-0.0071265996, 0.020476552, 0.017235534, -0.0...  \n",
       "33  [-0.010636117, 0.01212832, 0.029030465, -0.086...  \n",
       "34  [-0.018388461, -0.006911759, 0.015190295, -0.0...  \n",
       "35  [0.007228276, 0.021961471, 0.031665433, -0.088...  \n",
       "36  [-0.008043373, -0.011165032, 0.031197485, -0.0...  \n",
       "37  [-0.0071265996, 0.020476552, 0.017235534, -0.0...  \n",
       "38  [-0.038686633, 0.0036908067, 0.02178414, -0.07...  \n",
       "39  [-0.018388461, -0.006911759, 0.015190295, -0.0...  \n",
       "40  [-0.004057311, 0.01868715, 0.01563467, -0.0808...  \n",
       "41  [-0.028552804, -0.0118231885, 0.00639494, -0.0...  \n",
       "42  [-0.027204884, -0.023552606, 0.019531347, -0.0...  \n",
       "43  [0.0032914313, 0.01059015, 0.009196502, -0.064...  \n",
       "44  [-0.0075815883, 0.02116889, 0.027429571, -0.10...  \n",
       "45  [-0.012517108, -0.014230472, -0.0019505646, -0...  \n",
       "46  [-0.0066825696, 0.002244388, 0.011106265, -0.0...  \n",
       "47  [-0.0066205882, -0.0075128363, 0.019882608, -0...  \n",
       "48  [-0.00826649, 0.019363934, 0.016988434, -0.080...  \n",
       "49  [-0.009709013, 6.357031e-05, 0.023912106, -0.0...  \n",
       "50  [-0.012295628, 0.015832268, 0.025340993, -0.09...  \n",
       "51  [-0.027908303, 0.017137818, 0.023856219, -0.06...  \n",
       "52  [-0.021185221, -0.0025146175, 0.01119325, -0.0...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db[\"transcriptions\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63be76da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how does llm work_</td>\n",
       "      <td># How does LLM work?\\n\\n[00:00:00] Hello and w...</td>\n",
       "      <td>[-0.027908303, 0.017137818, 0.023856219, -0.06...</td>\n",
       "      <td>0.549269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pydanticai fundamentals - outputting structure...</td>\n",
       "      <td># PydanticAI fundamentals - outputting structu...</td>\n",
       "      <td>[-0.033087507, 0.0036856267, 0.02514256, -0.07...</td>\n",
       "      <td>0.690942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pydanticai chatbot</td>\n",
       "      <td># pydanticAI chatbot\\n\\n[00:00:00] Hello and w...</td>\n",
       "      <td>[-0.012143856, -0.001205422, 0.013563879, -0.0...</td>\n",
       "      <td>0.692687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         video_title  \\\n",
       "0                                 how does llm work_   \n",
       "1  pydanticai fundamentals - outputting structure...   \n",
       "2                                 pydanticai chatbot   \n",
       "\n",
       "                                             content  \\\n",
       "0  # How does LLM work?\\n\\n[00:00:00] Hello and w...   \n",
       "1  # PydanticAI fundamentals - outputting structu...   \n",
       "2  # pydanticAI chatbot\\n\\n[00:00:00] Hello and w...   \n",
       "\n",
       "                                           embedding  _distance  \n",
       "0  [-0.027908303, 0.017137818, 0.023856219, -0.06...   0.549269  \n",
       "1  [-0.033087507, 0.0036856267, 0.02514256, -0.07...   0.690942  \n",
       "2  [-0.012143856, -0.001205422, 0.013563879, -0.0...   0.692687  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Learn about LLM\"\n",
    "search_result = vector_db[\"transcriptions\"].search(query).limit(3).to_pandas()\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "427ecdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# How does LLM work?\\n\\n[00:00:00] Hello and welcome to this video where we'll go into large language models and how do they work. We'll go into the theory and intuition about how models like chat, g, pt, Gemini, Claude, et cetera, how they work, the fundamental theory about it. ~~We will go into to get. ~~To give you intuition on how does it generate language, how can it understand language, et cetera.\\n\\nThis will be really interesting and hopefully that you'll get some intuition. You don't need to understand exactly the details, how it works. However, some basic intuition is good that you, you know that it's not magic, it's just mathematics and statistics. However, we won't go into much math and statistics\\n\\nwe will keep it simple and that you can understand it. Yes. Let's move on to the slides.\\n\\n**Kokchun Giang-1:** how does she GPT and other language models work? An introduction to large language models? How can we start with [00:01:00] text? How can we represent text for a computer? A naive approach. Start to understand that the computer, it can only understand numbers, it can only understand zero and ones. We need to somehow represent.\\n\\nThe text into numbers that the computer can understand it. This is our starting point. Computer doesn't understand text. It understands numbers, which can be represented in binary as ones and zeros. We need to represent text with numbers. This is our starting point. Suppose our vocabulary has these words.\\n\\nWe have, Hey, ~~Canon ~~fis do, sorry, this is in Swedish, but these are just a few words in Swedish vocabulary. Then one hot encoded vector would look like this. Have a vector. This means that this represent hay. If this is our vocabulary, and then we have zero on all the other ones. This is just the [00:02:00] word, Hey, ~~hay ~~can be represented with this.\\n\\nIn Swedish there's 126,000 words. Then we'll have a very huge vector if we will represent it as in this way. This is a term based approach to represent the words. Then we'll have a one, somewhere to represent one word, and then zero everywhere else. Is this a good approach?\\n\\nThat is the question. Get the very, we'll, get the very sparse vector. That means that we have a lot of zeros and just one, one, but we also want to have some semantic meaning between the words. What does the semantic meaning mean? For example, we have the word hello and the word bi. They should be somewhat close to each other as both are about greeting.\\n\\nHow are you, maybe it should be close as well. While a rabbit and a dog should be somewhat close to each other as both [00:03:00] our pets, a rabbit and a hare should be closer than a rabbit and a dog because they may look. More similar, they have more features that are similar and fish and goldfish should be very similar.\\n\\nThis is what we mean with semantic meaning. This is not captured by using this naive approach as we will only have a one somewhere since we have a rabbit and a dog. They are quite. Far away from each other in the alphabet. Then it means that~~ they, ~~they're not related at all~~ in ~~in the naive approach, but we want to have them more relatable that we can start to get the grasp of the language to start model and understand the language.\\n\\nThen we'll go further into embeddings. Then 2013 there was ~~a, ~~an article called Word to ve, how to Represent Words with Vector Embeddings that captures semantic meaning. This is a kind of the start [00:04:00] here. Here I have ~~a. ~~A Cartesian coordinate system where we have a size as a feature and we have loves hay as another feature.\\n\\nThis is just 2D but we could expand this to many dimension, but it's impossible to show it. We have here a tiger that ~~is, ~~has a large size, but it doesn't love hay. While we have a rabbit here that is smaller size but loves hay. Where does cow and calf go? That is the question. You can, for example, say that cow, it's quite large in size.\\n\\nYou can say two here. And then it also loves hay. It eats hay. While the calf, it's somewhat smaller in size, but also loves hay. You can see that, and they are closer. They are ~~close to they are in ~~in this place here. This is how you can represent them. These are vectors.\\n\\nYou can draw lines or you can draw arrow to these, and you get vectors. [00:05:00] However, we have larger dimensional embedding vectors of course, because these embedding vectors, they become larger and larger when you have more and more features. ~~If we could have more. Size and love, say we could have domesticated as one feature.~~\\n\\nWe could have for example, mammal as a feature we could have living in water as a feature, et cetera. We could have a lot of features. ~~We can have yeah, there's a lot. ~~To find similar words, we use a dot product, which gives co-sign similarity between the vectors. ~~We take we find the co-sign similarity.~~\\n\\nThe cosign similarity is basically just an angle. We ~~took, ~~take a look at the angles between two vectors and see which one is closest. That is the idea to ~~get then we ~~get the semantic meaning. We can also do an interesting thing is that we can do some calculations with the vectors.\\n\\nWe could add vectors and subtract vectors to get different types of results. That is quite cool. Moving on. In 2017, we have this paper. Attention is all you need. This is the [00:06:00] Transformers architecture, and this is what all language models are based on as of today. We start here, the goal is to predict the next word based on the previous sequence.\\n\\nYou have a sequence of words and you want to predict the next word that is the goal. For example, here in Swedish, there's who I lag it is how are you and who more do if there's two are, then there's lag. Who more than is do it is like, how are, how is. How are you? For this we need to understand the context through the attention.\\n\\nFor example, I am cool. The cool it refers to I, then it means that it's the coolness, I am cool. However, the ice cream is cool. It's referring to the ice cream. If it's referring to the ice cream, then this cool, it means something else. ~~Then this cool up here. ~~This cool [00:07:00] is referring to the person I, and this cool is referring to the ice cream where it's.\\n\\nCool as in low temperature. Depending on the context the same word could have different meanings. This is where the attention is. ~~All you need is very very neat. ~~Also here it goes away from previously it was used in RNNA lot recurrent neural network, but here it's go, it's removing that all along.\\n\\nHere we compute similarities to see which words that determine the context for cool as it has different meanings in different contexts. ~~Computing similarities to see. The words. Okay. Similarities. ~~With the transformer, we can generate text word by word using previous words as contexts. It's jumping around and see the different similarities, scores and see that.\\n\\nOkay. Is this one that will determine. Cool the most while death and is not determining cool as much. How does it know what is determining it? It depends [00:08:00] on all the training data that this has gone. You have sent in a lot of training data and it has learned this patents. Now we can generate text word by word using previous words as context.\\n\\nFor example, like this, I am cool. I am, and then it looks into its training data and sees like cool, appears a lot of time in the training data, and then it'll predict cool with the highest probability. Then afterwards it predicts the word yo because that is also very common in this training data set that I have thought about in my mind.\\n\\nThen I am cool. Yo, it comes out. I'm cool. Yo Zap then it's yeah, depending on this training data set. As you can see this what it does is that it. Takes the sequence, send it in, and it'll predict. Cool. Then it'll send in this next sequence with I am Cool. It'll predict yo and we send in all this and then it'll [00:09:00] predict sap.\\n\\nThis is a little bit of simplification. It's not the really words that it predicts. It predicts something called tokens, but it's more more division of the word in different ways. But we don't need to go into that for simplicity. We'll think about it as words. Okay. Then we'll get a little bit further in time.\\n\\nWe get into GPT general pre-trained Transformers, and then this is trained with unsupervised learning on large corpus of text ~~is pre-training, it's trained on. The data ~~from the internet, basically. Using Internet's text, it can predict most probable next word to generate. Then when you train on much data, it become, it becomes something called emergent capability.\\n\\nIt's start to be able to find patterns ~~that you are not ~~that people are not sure about before. Then you can also add. Something called temperature, and we'll get variations and [00:10:00] creativity. What this means is that maybe ~~we don't need to pre, ~~we don't want to predict I am cool instead maybe it predicts I am super because super maybe was the third most probable word.\\n\\nBut since we have temperature, it becomes like, I don't need to pick the most probable word. I can pick some other word with some probability. The higher temperature it gets, the more ~~it. ~~It becomes more wild. That is to say it can pick other words ~~in its core, ~~in its training. Then ~~when ~~we can fine tune it to specific task using supervised learning that you can, for example, chat in a certain format.\\n\\nYou need to train it with a certain format that it should answer in this type of format. Here we have a supervised learning. Then in order to get it to become good to answer in a way that we want it answer, we have something called reinforcement learning with human feedback, [00:11:00] RLHF.\\n\\nWe let the model answer a set of question several times, you can generate a lot of different answers. We have different temperatures, we get different types of answers, and then we let. A lot of humans very lowly paid humans, unfortunately that will score these answers and feed back to the system how good these answers were.\\n\\nThe systems will try to maximize its scores, it gets scores, for example, it, you, it says one a type of answer and you give it back a score of four. But in a scale of 10, and then another answer, it gives seven another answer, five, et cetera, and it'll try to get the highest score all the time to satisfy the humans.\\n\\nThe system will try to maximize its scores. Example, an answer of how to make a bomb will get low scores, for example, and model will try predict which type of answers that humans [00:12:00] like. Then, after RLHF, ~~we have ~~we have come to the part of we have a chat, ~~GPT three point ~~GPT, 3.5. It's like the first chat, GPT to make it very simple.\\n\\nI've skipped a lot, I've skipped some of the details. But this I think it's the intuition that you need to see that. Yes, now we have a model that we can chat with and ~~then ~~then there's a lot of different improvements in a lot of different models and and then a lot of variations as well that I haven't covered.\\n\\nBut I want to cover one more thing is that we want to make the model become more. Capable and understand more different things and ~~do ~~be able to perform different things. For example, we can send in a video and it'll understand it. ~~We, ~~it can produce a video, it can produce an image, we can send in an image and it'll understand that, et cetera.\\n\\nHow to do that is that we've gone into large multimodal models. LMM. Here LLMs [00:13:00] are language models and not good at, for example, math. It cannot do computation very well because ~~it's, ~~that's not its main purpose. Also it can't answer questions on things that happens after its training cutoff.\\n\\nThen what you can do is that it can however, use tools to handle this. For example, we can use tools such as a calculator to do computations because that will be much better than using. The raw training data that we have, and we can use Google search to enhance our context.\\n\\nWe can get more context of the things that ~~is ~~outside of our cutoff or more specific things that it becomes visible for the model to use to generate an answer. We can have an image generator to generate image ~~when ~~when someone asks for an image. We can also send, when someone sends an image, we can use~~ i ~~other AI tools such as image recognitions to try to understand the image ~~to ~~to generate text based on it and et [00:14:00] cetera with video ~~et.~~\\n\\nLMS can also process and understand other inputs such as video, image, audio, et cetera. You can talk to it, it can generate back speech with text to speech. And using the newer it becomes more and more natural as well ~~in, in the text. ~~In the speech. ~~Yes, I.~~\\n\\nin this video we have gone through LLMs and how do they work and to get some intuition about how it works. We have gone into ~~some ~~some very brief concepts of different parts for an LLM to work and but not gone into all the details. Of course, there's too much and we have tried to skip.\\n\\nSome of the math that it becomes quite simple to understand. Starting with like how to represent text and then going more towards training on how the attention works. Then going into training on the internet data to get pre-trained, GPT and then going further into supervised learning and reinforcement learning with human feedback that we [00:15:00] can get the chat.\\n\\nChatting format that we are used to and then moving further into ~~large ~~large multimodal lang models where it can be more capable to use different types of tools and understand different type of inputs and getting different types of outputs. I hope that you have learned a lot in this video ~~and ~~and see you in the next one.\\n\\nBye.\\n\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LLM prompt\n",
    "response = vector_db[\"transcriptions\"].search(\"LLM\").to_list()[0][\"content\"]\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1ff49",
   "metadata": {},
   "source": [
    "# Testing agent with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9402b459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output='In 2024, **Jannik Sinner** made history by winning his maiden Grand Slam title at the Australian Open, becoming the first Italian man to do so in the Open Era. He also became the first Italian man to reach World No. 1.')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "rag_agent = Agent(\n",
    "model= \"google-gla:gemini-2.5-flash-lite\",\n",
    "system_prompt=(\n",
    "        \"\"\"\n",
    "        You are a tennis trivia expert\n",
    "        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\n",
    "        Be consise.\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "result = await rag_agent.run(user_prompt=\"give me something from year 2024\", message_history=None)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "34e261f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='\\n        You are a tennis trivia expert\\n        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\\n        Be consise.\\n        ', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 113204, tzinfo=datetime.timezone.utc)), UserPromptPart(content='give me something from year 2024', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 113426, tzinfo=datetime.timezone.utc))], run_id='e629752f-0319-4311-93bb-0f0ebc33ffcf'),\n",
       " ModelResponse(parts=[TextPart(content='In 2024, **Jannik Sinner** made history by winning his maiden Grand Slam title at the Australian Open, becoming the first Italian man to do so in the Open Era. He also became the first Italian man to reach World No. 1.')], usage=RequestUsage(input_tokens=48, output_tokens=56, details={'text_prompt_tokens': 48}), model_name='gemini-2.5-flash-lite', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 769222, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='Yp06aZvTJ5K0nsEPkuX0wA8', finish_reason='stop', run_id='e629752f-0319-4311-93bb-0f0ebc33ffcf')]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "eab183a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='\\n        You are a tennis trivia expert\\n        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\\n        Be consise.\\n        ', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 113204, tzinfo=datetime.timezone.utc)), UserPromptPart(content='give me something from year 2024', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 113426, tzinfo=datetime.timezone.utc))], run_id='e629752f-0319-4311-93bb-0f0ebc33ffcf'),\n",
       " ModelResponse(parts=[TextPart(content='In 2024, **Jannik Sinner** made history by winning his maiden Grand Slam title at the Australian Open, becoming the first Italian man to do so in the Open Era. He also became the first Italian man to reach World No. 1.')], usage=RequestUsage(input_tokens=48, output_tokens=56, details={'text_prompt_tokens': 48}), model_name='gemini-2.5-flash-lite', timestamp=datetime.datetime(2025, 12, 11, 10, 30, 58, 769222, tzinfo=datetime.timezone.utc), provider_name='google-gla', provider_details={'finish_reason': 'STOP'}, provider_response_id='Yp06aZvTJ5K0nsEPkuX0wA8', finish_reason='stop', run_id='e629752f-0319-4311-93bb-0f0ebc33ffcf')]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mess = result.all_messages()\n",
    "all_mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3b12847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'part_kind': 'system-prompt',\n",
       "  'content': '\\n        You are a tennis trivia expert\\n        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\\n        Be consise.\\n        '},\n",
       " {'part_kind': 'user-prompt', 'content': 'give me something from year 2024'},\n",
       " {'part_kind': 'text',\n",
       "  'content': 'In 2024, **Jannik Sinner** made history by winning his maiden Grand Slam title at the Australian Open, becoming the first Italian man to do so in the Open Era. He also became the first Italian man to reach World No. 1.'}]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readable_history = []\n",
    "for message in all_mess:\n",
    "    for part in message.parts:\n",
    "        part_kind = part.part_kind\n",
    "        content = part.content\n",
    "        readable_history.append({\n",
    "            \"part_kind\" : part_kind,\n",
    "            \"content\" : content\n",
    "            })\n",
    "readable_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a38b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2023, **Jannik Sinner** was instrumental in Italy winning their first Davis Cup title since 1976. He went undefeated in singles throughout the tournament, capping it off with a crucial victory in the final against Australia.\n"
     ]
    }
   ],
   "source": [
    "result2 = await rag_agent.run(user_prompt=\"give me something from year 2023 link that to the tennis player you already talked about\", \n",
    "                              message_history=result.all_messages())\n",
    "print(result2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4bc766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemPromptPart(content='\\n        You are a tennis trivia expert\\n        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\\n        Be consise.\\n        ', timestamp=datetime.datetime(2025, 12, 10, 13, 20, 8, 410816, tzinfo=datetime.timezone.utc)), UserPromptPart(content='give me something from year 2024', timestamp=datetime.datetime(2025, 12, 10, 13, 20, 8, 410849, tzinfo=datetime.timezone.utc))]\n",
      "------\n",
      "\n",
      "SystemPromptPart(content='\\n        You are a tennis trivia expert\\n        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\\n        Be consise.\\n        ', timestamp=datetime.datetime(2025, 12, 10, 13, 20, 8, 410816, tzinfo=datetime.timezone.utc))\n",
      "------\n",
      "\n",
      "\n",
      "        You are a tennis trivia expert\n",
      "        You always reply with some fun and interesting trivia from the professional tennis year the user choose.\n",
      "        Be consise.\n",
      "        \n",
      "------------------\n",
      "\n",
      "[TextPart(content='In 2024, **Jannik Sinner** achieved a career-high world No. 1 ranking, a remarkable feat achieved after winning his first Grand Slam title at the Australian Open.')]\n",
      "------\n",
      "\n",
      "TextPart(content='In 2024, **Jannik Sinner** achieved a career-high world No. 1 ranking, a remarkable feat achieved after winning his first Grand Slam title at the Australian Open.')\n",
      "------\n",
      "\n",
      "In 2024, **Jannik Sinner** achieved a career-high world No. 1 ranking, a remarkable feat achieved after winning his first Grand Slam title at the Australian Open.\n",
      "------------------\n",
      "\n",
      "[UserPromptPart(content='give me something from year 2023 link that to the tennis player you already talked about', timestamp=datetime.datetime(2025, 12, 10, 13, 20, 26, 883897, tzinfo=datetime.timezone.utc))]\n",
      "------\n",
      "\n",
      "UserPromptPart(content='give me something from year 2023 link that to the tennis player you already talked about', timestamp=datetime.datetime(2025, 12, 10, 13, 20, 26, 883897, tzinfo=datetime.timezone.utc))\n",
      "------\n",
      "\n",
      "give me something from year 2023 link that to the tennis player you already talked about\n",
      "------------------\n",
      "\n",
      "[TextPart(content='In 2023, **Jannik Sinner** reached the ATP Finals championship match, where he ultimately fell to Novak Djokovic. He also led Italy to victory in the Davis Cup that same year, showcasing his growing impact on the sport.')]\n",
      "------\n",
      "\n",
      "TextPart(content='In 2023, **Jannik Sinner** reached the ATP Finals championship match, where he ultimately fell to Novak Djokovic. He also led Italy to victory in the Davis Cup that same year, showcasing his growing impact on the sport.')\n",
      "------\n",
      "\n",
      "In 2023, **Jannik Sinner** reached the ATP Finals championship match, where he ultimately fell to Novak Djokovic. He also led Italy to victory in the Davis Cup that same year, showcasing his growing impact on the sport.\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for content in result2.all_messages():\n",
    "    print(content.parts)\n",
    "    print(\"------\\n\")\n",
    "    print(content.parts[0])\n",
    "    print(\"------\\n\")\n",
    "    print(content.parts[0].content)\n",
    "    print(\"------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1839b05",
   "metadata": {},
   "source": [
    "## Testing the deployed function app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7da8b627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "url = f\"https://rag-youtube.azurewebsites.net/rag/query?code={os.getenv('FUNCTION_APP_API')}\"\n",
    "\n",
    "response = requests.post(url= url, json= {\"prompt\": \"advanced SQL\"})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf7a6e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'advanced SQL',\n",
       " 'bot_response': {'video_title': 'sql analytics course with duckdb - subquery tutorial',\n",
       "  'video_link': 'https://www.youtube.com/watch?v=aZQtKjWfaDw',\n",
       "  'answer': 'Ro Bt my friend! You\\'re diving into the exciting world of advanced SQL with subqueries! In the video \"sql analytics course with duckdb - subquery tutorial\", you\\'ll learn that a subquery is essentially a query nested inside another SQL query, enclosed in parentheses. It executes first, and its result is then used by the outer query. This powerful technique can be applied within SELECT, FROM, WHERE, or HAVING clauses to construct more complex and powerful queries.\\n\\nSubqueries are incredibly versatile, allowing you to perform operations like filtering data based on an aggregate result (e.g., students with scores higher than the average) or checking membership against a list of values returned by another query. The video further explores different types of subqueries, including multi-row subqueries used with the `IN` operator, and the more advanced correlated subqueries. A correlated subquery is particularly interesting because it depends on column values from the outer query and executes once for each row processed by the outer query. This enables highly granular filtering, such as identifying students with math grades higher than the average of their *own* specific classes.\\n\\nWhile subqueries are a fundamental tool for any data engineer, remember that for extremely complex logic, Common Table Expressions (CTEs) can often provide a more readable and maintainable alternative. But mastering subqueries is a crucial step in your advanced SQL journey!'}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84892a1",
   "metadata": {},
   "source": [
    "# Testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "022d0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = \"http://127.0.0.1:8000/rag/description-gen\"\n",
    "response = requests.post(url=url, json={\"prompt\": \"video about sql\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afc87d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'video about sql',\n",
       " 'bot_response': {'video_title': 'sql analytics with duckdb - introduction',\n",
       "  'video_link': 'https://www.youtube.com/@AIgineer',\n",
       "  'answer': 'Ro Bt my friend!\\n\\nThe video \"sql analytics with duckdb - introduction\" provides an excellent starting point for understanding SQL and its practical applications, especially with DuckDB. It highlights the common pitfalls of managing growing datasets with tools like Excel, such as data duplication and inconsistencies, and then introduces SQL and relational databases as robust solutions.\\n\\nFrom an AI and Data Engineering perspective, SQL is the bedrock of data manipulation and analysis. It\\'s not just about querying data; it\\'s about defining, controlling, and transforming it. The video clearly explains the different facets of SQL through DDL (Data Definition Language), DML (Data Manipulation Language), DQL (Data Query Language), and DCL (Data Control Language). This categorization is crucial for understanding how you interact with databases at various levels  from creating schemas to retrieving insights.\\n\\nDuckDB is presented as a powerful, embedded, and highly performant analytical database, ideal for local data analysis and even serving as a lightweight data warehouse in ETL pipelines. This is particularly relevant in today\\'s data landscape where in-memory and embedded databases like DuckDB offer significant advantages for data scientists and engineers working with medium-sized datasets, allowing for rapid experimentation and analysis without the overhead of client-server architectures. Its seamless integration with Python and Pandas makes it an indispensable tool in the data science ecosystem.\\n\\nUnderstanding SQL and tools like DuckDB is fundamental for anyone looking to build a career in Data or AI Engineering, as it underpins almost all data-centric operations.'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()\n",
    "#.get(\"bot_response\")[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f0091c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SQL, DuckDB, SQL analytics, data engineering, AI engineering, data science, relational database, OLAP, OLTP, DDL, DML, DQL, DCL, data consistency, data duplication, data manipulation, data querying, data transformation, ETL, ELT, data warehouse, business intelligence, machine learning, Python, Pandas, data analysis, database management, embedded database, scalability, performance, data constraints, unique identifiers, data modeling, SQL introduction, data insights, local data solutions, modern database, structured query language, data architecture, analytical queries'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = \", \".join(response.json().get(\"bot_response\")[\"keywords\"])\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e2f68a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = \"http://127.0.0.1:8000/rag/query\"\n",
    "#url = \"http://127.0.0.1:7071/rag/query\"\n",
    "response = requests.post(url=url, json={\"prompt\": \"video about api's\"})\n",
    "svar = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "72d8d053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parts': [{'content': '\\n        You are an expert Youtuber in Data Engineering and AI Engineering.\\n        Always start with the greeting; \"Ro Bt my friend!\"\\n        Always use the retrieved knowledge of the Youtube transcripts from your tool to answer the question. \\n        Always point to the video title you are referring to.\\n        But do add more flavor from your expertise about the subject, keep it brief.\\n        ',\n",
       "    'timestamp': '2025-12-11T13:04:13.873300+00:00',\n",
       "    'dynamic_ref': None,\n",
       "    'part_kind': 'system-prompt'},\n",
       "   {'content': \"video about api's\",\n",
       "    'timestamp': '2025-12-11T13:04:13.873328+00:00',\n",
       "    'part_kind': 'user-prompt'}],\n",
       "  'instructions': None,\n",
       "  'kind': 'request',\n",
       "  'run_id': '67043da2-0327-4890-bd37-d022375e2fbb',\n",
       "  'metadata': None},\n",
       " {'parts': [{'tool_name': 'retrieve_matching_video',\n",
       "    'args': {'query': 'API'},\n",
       "    'tool_call_id': 'pyd_ai_acc13074e3264e0d98c1949d9d2ce4d3',\n",
       "    'id': None,\n",
       "    'provider_details': {'thought_signature': 'Cu8BAXLI2nxRrxnkgZsZdF624+a7EDxPJIu+VMNtxDUvzfNuTFi+ZdSYqWkNhVPEcMMR3BfKeB2pfSgb42BVqTKy80axfIld/HxR9mS/OlWZ0m4IC2Z3c4AhWkilCPdRtyJmKfWfrFJ9z0P7PoLjyrmgyQnhHX9JYoDYtx8X+Q61qAjZahYk0wGqa7yhmQNcTSkWKafVrw6zyvdDuf0lUV4YFJELpTHB8h1P9ePyo1Rq4xhCfk8cF5nZP8F6095lmyZLGSvHRhAxaxvMOOwv6QoLGsF7KbmhpOqRAPLzowjUg6qhEelezN19Kmxu/H64UvA='},\n",
       "    'part_kind': 'tool-call'}],\n",
       "  'usage': {'input_tokens': 225,\n",
       "   'cache_write_tokens': 0,\n",
       "   'cache_read_tokens': 0,\n",
       "   'output_tokens': 65,\n",
       "   'input_audio_tokens': 0,\n",
       "   'cache_audio_read_tokens': 0,\n",
       "   'output_audio_tokens': 0,\n",
       "   'details': {'thoughts_tokens': 48, 'text_prompt_tokens': 225}},\n",
       "  'model_name': 'gemini-2.5-flash',\n",
       "  'timestamp': '2025-12-11T13:04:14.952210+00:00',\n",
       "  'kind': 'response',\n",
       "  'provider_name': 'google-gla',\n",
       "  'provider_details': {'finish_reason': 'STOP'},\n",
       "  'provider_response_id': 'TsE6aei2M6S_xN8P0_7CiQw',\n",
       "  'finish_reason': 'stop',\n",
       "  'run_id': '67043da2-0327-4890-bd37-d022375e2fbb',\n",
       "  'metadata': None},\n",
       " {'parts': [{'tool_name': 'retrieve_matching_video',\n",
       "    'content': \"\\n        Video title: api trafiklab (1),\\n        Content: # API trafiklab\\n\\n[00:00:00] Hello and welcome to this video where we'll go into getting data from an API. And the API that we've chosen is Trafiklab. And from this API, you will be able to get data on public transport. \\n\\nIt's good to, understand a little bit about the data set so that you could, for example, monitor if there's delays in the trams or trains. So yes moving on, we'll go into the web browser directly now.\\n\\nSo here I'm in the web browser and I've gone into Trafiklab.\\n\\nse slash API. Let me move myself here.\\n\\nIn Traffic Lab SC slash api~~ we have ~~we have several APIs that we can work with. And~~ one, ~~the ones that we will pick are those that are in s robot. So here race robot stalled. It's tabella here. You can get the timetables for different stops.\\n\\nSo we'll go in and ~~see ~~see more details, how to work with this one. [00:01:00] And this re robot plan is used for ~~planning~~ planning your trip. For example, you want to travel ~~from Sweden to ~~from UBO to Stockholm, ~~for example. ~~Ubo to Malmo. You can find out. ~~The trips~~ which type of trains and buses there are and their stops, et cetera.\\n\\nSo this is quite interesting and it's an open API so that you can use it for free. The only thing you need to do is ~~to ~~to create an account and register ~~for ~~for these APIs to use. Firstly. ~~You, ~~if you scroll up here, there's Minna sidor or my pages. So clicking on this one we'll go in here and you can create an account for me, I will just log in with GitHub so that you can do if you have a GitHub.\\n\\nAnd here~~ I have ~~you should create your own projects. So basically I have a few projects, I have streaming data and I have this testing and there's also a sandbox here. So you should create a new project.[00:02:00] \\n\\nSo when creating a new project, you give it a name. I will give it a, for example, a travel planner, ~~for example, ~~and ~~you can have a homepage if ~~you can link to a homepage if you want, but if you don't, it's okay. You can choose what type of project it is. It's an educational project and open source repository if you have that.\\n\\nBut~~ unless you don't need, ~~you don't need to. ~~And ~~description is also good to have or it's mandatory because these are optional. Description learning. Let's see. Learning. Lab a p. Same.\\n\\nSo here ~~I have~~ I have the travel planner ~~and ~~and now you should get your API keys ~~and to get the ~~. It's basically like this. ~~You choose here~~ you choose which type of API you want. And the one we want to pick is a robot\\n\\nme see here. Race robot version 2. 1. And then you click add key to project and you will get an [00:03:00] API key. \\n\\nHere are the API keys. I won't go down to the API keys because I don't want to share them with you. Instead you should go down there and copy ~~that key~~ that specific key because we will use it ~~in order to get ~~in order to use this page~~ get the ~~APIs.\\n\\nSo moving on to when you have the key store it in a dot ENV file, I'll show you how that looks soon. Or actually we can go there directly. I'll go to Visual Studio Code. And here~~ in this~~ in this project, I'll open a new terminal and let's see what I will do. I will do touch dot ENV.\\n\\nSo that we get a dot ENV file and inside this dot ENV file, you should write API equals to your API key the ones that you've copied. So just copy and paste it here and then we'll go back to Visual Studio. And we'll go back to. Traffic [00:04:00] lab and inside of API keys or actually documentation.\\n\\nYou've got the documentation and you're going to API overview, right here, and we can go into this robot started stability, for example, click on this one and here there is a example on how you call this one. So you basically just copy this one. Departures and arrivals, right? So you copy this one in order ~~to ~~to get the data from this one.\\n\\nAnd, but then you need to create an if you're using Python, which we're using in this course, and in this lecture we will~~ we'll ~~use the request library and we will do a get request to this end point and using our API key. And also you can go down here to read a little bit more about different options and what they mean.\\n\\nSo I won't go through them instead I will leave it to you for you to read. But let's go back to Visual Studio Code now [00:05:00] and let's set up different things. So let me do this. I will create the virtual environment. So uvvnv source dot. So now I've activated my virtual environment and I will do uv pipinstall.\\n\\nWhat do I need? I need ipykernel, of course, because I will work with Jupyter Notebook. I also need pandas. And I also need And let me think, what do I need requests? I need yes, starting with this. I think not dot ENV of course. So Python dot ENV. One thing with env it is for so that you can store your secrets.\\n\\nI'll show you what that means soon. So let's create a Jupyter notebook file now. So touch\\n\\nlet me see touch [00:06:00] API, public transport, ipnb. Okay. And now we'll open this one.\\n\\nSo we'll do an EDA on public transport traffic lab API. And then I'll change this to my virtual environment.\\n\\nSo let's start with testing out our dot ENV. ~~So from dot, let me change this to Python and I'll increase it, making it a little bit bigger. ~~So from dot ENV import load dot ENV. And we need to import OS as well in order for us to get the environment variable and then we'll do import requests .\\n\\nAnd starting with our load. dnv, we can do like this. Start with load. dnv. In general, you need to have a path here. But~~ in, ~~when you're in Jupyter Notebook, you have the path is based on where ~~this ~~this file is so since e NV is a sibling [00:07:00] to this file and this Jupiter notebook, ~~then~~ then do ENV will be found.\\n\\nSo when we do low e nv and then we can do os get ENV, and we take the API, if we are going to nv, we can see that it's called, it's just called. I'll call it API key. And then I will do API key here. And if I run this one, we can see we get dot. That means that ~~we~~ the Jupyter Notebook finds this dot DNV.\\n\\nOkay, great. So now I'll just pause the video and I'll put in my real key. So remember, the real key can be found ~~in ~~in strategic lab where you're logged in.\\n\\nI've added my real key and of course I won't show that to you. It's important that you add do ENV ~~to your ~~to your.gi nor file. If it isn't there already, so that is to [00:08:00] make sure that it's not tracked by Git and that you don't accidentally push it to a public GitHub repository.\\n\\nSo this is in order for us to so because we don't want to write out the API key here. Directly because when I push it~~ you ~~then people will see it ~~in my directory, ~~in my repository and can use my API key. So secrets store it in DNV and load it using Load d nv. Okay, so then this one, I can just call it API Key equals to this.\\n\\nSo if I run this one it, it is stored in API key, but~~ I ~~I don't write it out so that you can't see what it is. However, I will use it later on. So now we'll go into Trafiklab. So here in Trafiklab, let me see. So in traffic lab we have if we go into our ~~this robot~~ [00:09:00] this robot route planner, you can start here and you can see this example call.\\n\\nLet's copy this one. So it says. This example called ~~receive ~~retrieves all routes from Stockholm Central Station ~~seven~~ this ID to Malm Central Station, another ID. So I just copy this one and I go back to my Visual Studio code and I will call URL equals to this, make it into a string and make it into an F string.\\n\\nAnd then I will also make this API key into a variable so that I can use this. API key inside of this URL. Okay so since we have, we can read it out here. So api. resrobot. se version 2. 1 slash trip. So ~~this is the end, so it's~~ it's the API. We query, we're using the format. This is an [00:10:00] option. The option is a format which is JSON.\\n\\nAnd another option, origin ID equals to this ID. And dest ID is destination ID is this ID here. And then we have pass list equals true and show passing points equals true. Actually, I'm not sure what both of them are. ~~It's ~~it's listed in the documentation in the web page, which you can read about.\\n\\nAnd then most important, very important, is that we have the access ID, which is our pass list. API key, right? So that is very important. And we get the API key from our dnv. So that is how everything is connected. So now we have our URL. So this is an endpoint for us to retrieve data. So in order for us to get the data we need to do requests dot get, and basically we just put in the URL.\\n\\nAnd we call [00:11:00] this response equals to this response. And I run this one response 401. Why is that? Let me pause and I will pause and debug this.\\n\\nOkay, I found a problem. First of all, I wrote response. txt to see~~ to see what~~ what text we get. And we get an error code, which says API auth, error text access denied. Okay, then I thought based on this, what could be the problem? Maybe the API key is wrong. So what did, ~~I just, ~~I typed out API key and saw what I get.\\n\\nDot dot. How strange, even if I re ran this one, I got API key. Because this is already loaded, right? That is how it works in Jupyter Notebook. When it loads one time, it won't load again. So this is important if you have~~ if you ~~started with something else than ~~your API, ~~your real API key. Just do restart.\\n\\n~~Restart this one, ~~and now I will [00:12:00] remove this cell here. And if I run this one, now it should work. Yes, now it works. We can see there's a response. txt, and we have Stockholm Central Station and a lot of things here. So instead of getting it as a text, I want to get it as a JSON object. ~~So as a JSON, ~~so JSON object is basically in Python is represented as a dictionary.\\n\\nSo you have a dictionary of a list and you have a lot of other things. So in dictionaries, a very important thing what I usually do when I start working with API where I get JSON data is that I usually Try to explore this API, explore this dictionary. So starting with this, let's continue.\\n\\nWe can do like this. Let's see. Response. json we can get let me see. Response. json, we can call it results,[00:13:00] \\n\\nresponse. json, result, and we do result. keys, and we can see what type of keys we have. So we have trip, we have result status, and technical messages, server version, et cetera. So there's a lot of things here. And actually in my Jupyter notebook~~ in the. ~~In the lecture note, you can see that I've explored most of them, I think.\\n\\nHowever, ~~you should also ~~you should also check them out. What we can do is like this. Since it's a dictionary, we can take out the trip here. And we can see that it's a list. It starts with brackets here. If it's a list, we can do like this. We can do length of this. And we can see seven.\\n\\nOkay, there was seven here. We could do a result of result status and see what that is. Okay. ~~Some time diff ~~some kind of metadata. I'm not sure what this, ~~what it ~~is, but ~~you should, ~~you can read in the [00:14:00] documentation in case you wonder. We can continue here technical messages, and see what we get here.\\n\\nOkay, so technical messages. We get ~~some, ~~something that I don't understand either. Let's continue going on down here and we'll take ~~serve ~~server version. Probably I can understand what that is. Dialect version plan R T S. I think those are not so relevant for us. So we will continue with the trip.\\n\\nSo results of trip. So you can see here we have it's a list and now it's seven items, right? So what we can do with this is that we could ~~loop through it. So if it's a list, we can ~~loop through it. We can loop through the list. And actually in the lecture notes, I have created A function~~ of this ~~of the get request, basically.\\n\\nSo that is a little bit [00:15:00] more elaborate and ~~you can~~ you can choose it to use. ~~And we can ~~however, here ~~I will I will not write, or ~~I can write out the function, actually. Because we will use it later on. Let's do that. Let's go into the function. I will create a function of it. I will just copy from the lecture note and I will explain that.\\n\\nThis is what I did for the function. We can remove the API key as we had it earlier. So basically it's the same as before. We have a URL, however, the origin ID and destination ID I put it into as parameters so that you can send them in as arguments ~~in order ~~if you want to Choose other destinations and origins.\\n\\nNow, the first one is Stockholm and the other one is Malm, but I want to get ~~the ~~just the body later on. So then afterwards we do a try ~~because how come? ~~Because the response object, the request. get, it can fail, right? It can fail with different [00:16:00] exceptions. And if it has an exception we also do response.\\n\\nraise for status. So in case It'll raise an HTP error if it occurred. ~~Four, 400 x four xx and five xx. ~~So if you get status code 400 something, 500 something, then it's some kind of HTTP error. And that is what ~~I~~ we're catching here with the accept. So this one. Result equals getTrips and we can get result.\\n\\nkeys. And this is basically the same ~~as~~ as I showed before. So now we have the trip, we get result of trip, right? So we can call this, let me see, we can call this we can call, for example exampleTrip equals to this one, and I will take the zero of it. Example trip of, so if I do example trip now, you can see that we get the first one.\\n\\nSo origin [00:17:00] is in Stockholm and destination is in Gteborg, central Stockholm. Interesting. Yeah, I changed also here, this is another ID than the one I used before. So this one, this idea is for Gteborg, but how do we know which idea corresponds to which city or which stop? That, that will come back to later on in in the next section here, but we have Gteborg and Stockholm.\\n\\nSo let's continue. We can we can figure out a little bit more things here. Here we can go into we can go in to example trip of for example we can go into distinct origin, and we can see that we get Stockholm and and it has these keys and these values. We can continue copy this one and go into example trip of destination.\\n\\nAnd we can see that, okay, Gteborg Centralstation, et cetera, cool. [00:18:00] And you can explore more things here, but something I thought was quite interesting was so if you go into exampletrip.\\n\\n~~key, exampletrip, ~~you can run this one. And you can see here, origin, destination, and we have service days. Actually, we can do exampleTrip. keys to find out what we have. So origin, destination, service days, legList is quite interesting. So I'll do legList. And this one, here we can see a lot of information. We have origin, we have destination.\\n\\nSo we have several destinations, it seems. ~~So it seems to be, ~~so we have Stockholm here, and then we have Karlstad, so we can continue to find out different types of stops. ~~Leg list, and then we take out leg. ~~[00:19:00] Actually, ~~this ~~these names, I'm not sure what they stand for, but~~ they are in, ~~this is how they coded the response object.\\n\\nSo we get the list here. This is quite interesting. So let's do length of this list. I want to see how many there are here. Okay. Two. I'll copy this one.\\n\\nOkay. For example, I will pick the zero\\n\\nand in the zero, we have origin destination. I can do dot he's. And we can see we have origin, destination, journey status, stop. It's quite interesting. So I'll continue, copy this one. I'll go [00:20:00] into stops. And we can see, okay, stops. We have some key called stop. And then there's a list here. Okay, so we'll pick that one, stop.\\n\\nAnd we can see there's a list. Stockholm, Katrineholm, Hallsberg. Okay, see, ~~this is, ~~this requires some domain knowledge. ~~If you're ~~if you have traveled trains between Stockholm and Gteborg. These are common stations that exist there. So these are ~~the common stations or common, ~~the common stops, ~~though.~~\\n\\nOkay, so this is quite interesting. So we could continue here and we could actually call for example, these are different stops, right? We could call it example stops, example, stops like this. And then I will loop through this one. So I will do like this. For stop [00:21:00] in example stops, and I can do stop dot get name.\\n\\nSo basically get the same as using bracket notation. However, it won't return an error if the key is missing. Instead, it will give you none if the key is missing. So colon stop dot get for example, I will get the arrival time\\n\\nor departure arrival time. Yeah, I could take departure time as well. Okay, let's see. Yeah, I need curly braces because I want to make a dictionary here. So basically I'm doing a list comprehension of the dictionary. So here we can see, okay, we started with Stockholm Central Station. We go into Katrineholm, Hallsberg, Degerfors, Kristinehamn and Karlstad.\\n\\n~~Cool. ~~Cool. Maybe the other section, [00:22:00] because the length of these stops were two, right? And this ~~example stop that we, ~~example stops that we have, maybe this is half of the journey. I'm not sure this is worth finding out. Okay. But how did we get the body ~~as~~ as the stop as this as the ID, right?\\n\\nSo this, we need to use ~~some, ~~another API. Called ResRobotStopLookup, so I will go ~~into here, ~~into the browser, and we can see in the browser, we have a stop lookup, and ~~the stop lookup, ~~it will basically, ~~so ~~you have here, this is the API, you have location. name, question mark, input equals just a body, And format equals ~~Jason.~~\\n\\nAnd if you do ~~it, ~~the bar question mark, then you will, it's a ~~fussy ~~search so that it will match something that is similar to it. So basically here, you can see ~~what they said, like ~~the input ~~here, input as a, ~~as the option and [00:23:00] the search string, append the question mark for ~~fussy ~~search, that means we will find something ~~if we will find ~~for example, if we take.\\n\\n~~If we just take, ~~without the question mark, we'll only get Gteborg here. This is the data we get. We get the ID, external ID, name, ~~and ~~longitude, latitude, etc. But with Fuzzy Search, ~~we'll get everything that, ~~we'll get things that are similar. ~~So we get Gteborg etc. ~~So everything with Gteborg is matched here.\\n\\nOkay, cool. But then we find the external ID and then you use the external ID to put it into ~~your ~~your travel planner or your route planner or your ~~time ~~timetables. So moving back to Visual Studio Code.\\n\\nOkay so let's go into the stop lookup API. Here, we have stop look up API. We use this to find the ID. I will copy the URL. And basically I can copy all of this [00:24:00] here. I'll change this to Python. And then, okay, if you look into What we did here. So location is just the body. I have an F string so that I search and get the body.\\n\\nAnd this is a, an exact search. Now we don't have a question Mark and we have a API key and we have a result basically. So if I run this one,\\n\\nwe get the stop location or cord location,\\n\\nand we can do results let's see results of. Stop stop location or cord location. And I run this one and we can see here we have stop location\\n\\nand you can see name is yet the body\\n\\nand we can see, let's see, this is a list, right? So I can [00:25:00] do length of this list and it it contains 10 values. So basically, okay, we have 10 10 stops. Okay, so I will do result of, actually I will call this one, I'll remove this one like here, and I'll do stop locations equals to this, give it a variable, stop locations, and then I'll do stop locations, I'll run this one.\\n\\nSo we have for example, zero, stopLocation zero, and we could take stopLocation zero of stopLocation, and we can dot, take dot keys, and we can see the keys here. Okay, so it has an external ID, and it has a name. That is interesting. So how, what if I do like this? I copy this one, and I take out [00:26:00] name.\\n\\nCool. And if I copied this one and ~~I take out ~~I take out X ID, external ID, and we get, The external ID. So perfect. So this is how I got the ID for in order to put it into my route planner before. But if we have several, we want to pick the one that fits the best for us. Then basically ~~just ~~just do like this.\\n\\nWe can loop through this. Let's do four, stop location, in stop locations. Remember that stop locations is a list. Stop locations is a list of ten values. And inside of stop locations there is, so when I look through it, I will get This value and then I will get 0, 1, 2, 3, 4, up to 10 or up to nine.\\n\\nSo [00:27:00] here, this is a for loop and I want to have ~~stop location or stop equals ~~stop location or stop location, right?\\n\\nAnd why do I do that? We can see that I did it here because that is how it was structured. So I needed to take this. guy and do get the stop location. And from the stop location, I need to find the name, right? So then I can print the stop of name and stop of external ID. So here you can see, here are all the IDs for Gteborg.\\n\\nSo basically I can also do, I will do a little bit better formatting here. So print fString, stop,[00:28:00] \\n\\nstop like this, and it should have a left alignment of 50 character wide field. This is what it means using fString formatting. And then afterwards, after these 50 characters, I want to have My next string. So my next string is external ID. So then I get stop here and I get the external ID here. And then I could left align these also.\\n\\nSo that it comes into the external ID. So what I do is here stop. I need to do similar here. Like this, and I need to do it into F string like this,\\n\\nlike this. If I run this [00:29:00] one, let's see. Yes, nothing happens, but if I do colon 50 character wide, and this means left alignment, other side means right alignment. So then, perfectly, now it's now it's easy for me to find out ~~which~~ which one I want. So if I want to have, for example Volkswagen, then I just pick this ID here.\\n\\nOkay, great. And, yes, I've actually in my lecture note you should look into that. I have put it into a function which works. Which you can use for finding other locations that is actually quite good to have us as well. So I will copy that one. So this is from my lecture note, access ID from location.\\n\\nSo you just type in the location and it will find bind it for you. And basically it's the same idea as before, however, ~~one important, ~~some important things here is that I use [00:30:00] so this is quite interesting. Okay, so this you have seen before you get the response object. And you get it as a JSON, you put it into try because there can be exceptions.\\n\\nThen you do this for loop. And here is one important part, is that stopData equals to next of iter of stop. values.\\n\\n\\n\\nThat is the logic. And then it has an except for for some errors. But with this one, you can just use this function immediately. So access ID from location. We can, for example, get Malm, and we're doing a fuzzy search so that we have here, we see Malm, and you can get the external ID, Malm, here, another ID.\\n\\n~~You can~~ you can, for example, find a very small city here called Unsala. And you can see, yeah here's what's found in [00:31:00] Onsala. Actually, there's more stops in Onsala, but they don't have external IDs. And that's why ~~so ~~you can actually test it out without this if statement here. And ~~you will see ~~you will see more stations that corresponds to Unsala but~~ that, ~~that's why ~~I use this ~~I use this one in order for me to stop so that I can get the external ID because without the external ID, I cannot use it further anyway.\\n\\nAnd also ~~I will for example, ~~I can find something else. This interesting is another small city. And you can see, yeah, there's a lot here. Okay. ~~But ~~perfect. Now ~~we have~~ we have this and we can move on to another API. We can move on to time tables. So in time tables, we go into this robot and we have time tables here.\\n\\nAnd similarly, just copy this one here for departures and one for arrival. [00:32:00] You can pick the ones you want. ~~And let me. ~~Let me go up a little bit and find will actually go and copy. I ~~will ~~copy from my lecture note here. So this is for Korsvagen stop ID, because if I go up here, I have Gteborg Korsvagen is this ID.\\n\\nI will copy this one.\\n\\nAnd I go in here and store it. So this is the stop ID. I use this one to get the results I want. ~~And so you see it's another API endpoint. ~~And now actually I won't in this part, I won't put it into function, but~~ it's a, ~~it is good practice for you to put it into function ~~and ~~and do that and I will leave that for you to do.\\n\\nInstead I will just pick out some, I will show you using a data frame. Now ~~the ~~import pandas as pd, [00:33:00] we could do like this. If we write out results. Results is a JSON object, right? That looks like this departure and it has a lot of other things. However, I'll just pick out the departure.\\n\\nI'll actually throw this away because it will clutter my notebook. ~~When ~~otherwise I will do ~~the~~ the PD dot data frame of results of departure. That is where my data is. So df equals to this, df timetable, df timetable ~~dot~~ dot head, right? Head, like this, and you can see okay, so this is quite neat to work with.\\n\\nIf you have a data frame, it's much neater than working ~~with~~ with the ~~Jason ~~objects directly.[00:34:00] \\n\\nSo before we unnested the ~~Jason ~~objects and we looped through to get the things that we wanted, but now you can use the power of pandas and your panda skills in order to data process this. So basically you could do like this. dftimetable. columns for example. And we can see what ~~the ~~columns we have.\\n\\n~~We could do dftimetable ~~We can pick out ~~we can, ~~for example, clean it so that for example, we want to pick out what do we want? We want name and we can see, yeah, ~~this is, ~~these are the names we could pick out. What do we want more? We could pick out the stop and we have all the stops here.\\n\\nWe could pick out longitude, latitude, which you could use to draw in a map, dots in a map if you want. And see if you can map out the body direction [00:35:00] here, you can see where the directions are for the ~~trams on ~~trams and buses, we could ~~do ~~also ~~interesting in ~~which date we are using.\\n\\nSo date okay. Six is today and we can see the time and yeah, I just accessed the data. So you can see that Yeah. Okay. Here is a time in around one hour, one hour time, and you can see that we have, okay, ~~one~~ 116 ~~buses and tra ~~buses and trams included~~ that ~~that the departures ~~from ~~from Kosh wagon.\\n\\nOkay. So we could call this df timetable clean, for example. And then we could do DF timetable clean. And we could find out for example, name dot value counts. And we can see, yes, ~~these are the unique ones in ~~these are the unique buses and trams ~~in in ~~this station at this~~ station.~~\\n\\nParticular time frame from ~~from seven, ~~1911 to [00:36:00] 2011. And you can see, yeah, these are the most common ones and yes, ~~they~~ you have uncommon ones ~~are ~~express bus. They are ~~come, they're flying or they're. ~~Going further away and fleet transfer means flight transfer. So they're also more uncommon?\\n\\nYes. Okay. And with this~~ you, ~~you can do more exploratory data analysis, but I will leave that for you. So with this, I would like to thank you for watching this video and see you in the next one. Bye.\\n\\n,\\n        Content: https://www.youtube.com/@AIgineer,\\n    \",\n",
       "    'tool_call_id': 'pyd_ai_acc13074e3264e0d98c1949d9d2ce4d3',\n",
       "    'metadata': None,\n",
       "    'timestamp': '2025-12-11T13:04:16.339295+00:00',\n",
       "    'part_kind': 'tool-return'}],\n",
       "  'instructions': None,\n",
       "  'kind': 'request',\n",
       "  'run_id': '67043da2-0327-4890-bd37-d022375e2fbb',\n",
       "  'metadata': None},\n",
       " {'parts': [{'tool_name': 'final_result',\n",
       "    'args': {'answer': 'This video introduces how to work with APIs using Trafiklab, a public transport API. It covers essential steps like creating an account, registering for APIs, generating and securing API keys using a `.env` file, and making GET requests to API endpoints. The video also demonstrates parsing JSON responses, exploring dictionary structures, and extracting relevant data. It further shows how to use a stop lookup API to find IDs for locations, which can then be used with the main timetable API. Finally, it briefly touches upon using pandas DataFrames for cleaning and analyzing the retrieved data. As a data engineer, mastering API interaction is crucial for building robust data pipelines, allowing you to ingest real-time data from various sources and transform it for analytical or operational purposes.',\n",
       "     'video_title': 'api trafiklab (1)',\n",
       "     'video_link': 'https://www.youtube.com/@AIgineer'},\n",
       "    'tool_call_id': 'pyd_ai_fbf462812a764f2294f7721d75b86562',\n",
       "    'id': None,\n",
       "    'provider_details': {'thought_signature': 'CtEEAXLI2nynYt457Ybs0pg05vdS9FOp/7NzSeNDCEjEPwi92QajuYXrfTo9vX9MU4KOl10yAko6rl9IXjET4bkh7wtB+uaSoIY2K/A51jEJtIBWgaAxT+njN9dqm/MmcYbR2mHyzmMpDZgsfdnj41aYiNzQWI1DUK8w0KMsn6lSCi8PcxYYqhqtTXMM+YvDTsuowAJYR02nAGqJrgnfkdhcrSk034mqWJe7CTsS+V+/M3OccoSphnDsi3Pi2jprOnRTOR7ezcT9HGzk+DvkW6oP6bJDAOMSDWY054FDJVbNxoyGeWFmNCTJijDQVKwRBLZP52xSp4w5GT+1085QUDIwo6IIGiokXAvg2NMZnYkWThVYIzwq60O9ySx7l5lXhvgFGoEaRRcvAkp9VFV7ONhJ7H61EvGFkKfpwaws8jqWlke/WgQiUTeTiroLUgpkSmk1sGxZA7fxNmJU3PkQw6GBZwhLX96pPzVifweCF0yD8Im2WlQ/pBRg/MHJpNg9tGrdKq8MTvb3ETIDOcjPW+kBZMoRDCqdIdUIAiV53WvwJgQ8fr0fqF/fbotpjtazo6VaESYdfnJge/jB7xp2z70nirJ2vB2icP0ghfTDYfwO81+Ci9YAjVZ+ZbNkKaSPmmG7s0cP7K9e8wvHuT8+Byb3k5MVxLoP1/2I24OMPOQJgmZreS1Zr2bx7OEbPnRQIRoKOVBIkJChMUJI9+EI1F7xdd8CRpWbJoaAcDaN6l/S9pS9u3SRkXaQU0HXHQGou1R2nAb7QoHj+4eOLu37ou9d8y0='},\n",
       "    'part_kind': 'tool-call'}],\n",
       "  'usage': {'input_tokens': 7800,\n",
       "   'cache_write_tokens': 0,\n",
       "   'cache_read_tokens': 0,\n",
       "   'output_tokens': 317,\n",
       "   'input_audio_tokens': 0,\n",
       "   'cache_audio_read_tokens': 0,\n",
       "   'output_audio_tokens': 0,\n",
       "   'details': {'thoughts_tokens': 127, 'text_prompt_tokens': 7800}},\n",
       "  'model_name': 'gemini-2.5-flash',\n",
       "  'timestamp': '2025-12-11T13:04:18.953353+00:00',\n",
       "  'kind': 'response',\n",
       "  'provider_name': 'google-gla',\n",
       "  'provider_details': {'finish_reason': 'STOP'},\n",
       "  'provider_response_id': 'UsE6aYr3MKydvdIPi9_F-QQ',\n",
       "  'finish_reason': 'stop',\n",
       "  'run_id': '67043da2-0327-4890-bd37-d022375e2fbb',\n",
       "  'metadata': None},\n",
       " {'parts': [{'tool_name': 'final_result',\n",
       "    'content': 'Final result processed.',\n",
       "    'tool_call_id': 'pyd_ai_fbf462812a764f2294f7721d75b86562',\n",
       "    'metadata': None,\n",
       "    'timestamp': '2025-12-11T13:04:18.954502+00:00',\n",
       "    'part_kind': 'tool-return'}],\n",
       "  'instructions': None,\n",
       "  'kind': 'request',\n",
       "  'run_id': '67043da2-0327-4890-bd37-d022375e2fbb',\n",
       "  'metadata': None}]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svar[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ef3369c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ro Bt my friend!\\n\\nThe video titled \"api trafiklab (1)\" is an excellent resource if you\\'re looking to dive into working with APIs for data engineering. It specifically demonstrates how to interact with the Trafiklab API to retrieve public transport data. You\\'ll learn critical steps like setting up your environment, securely handling API keys using `.env` files, making GET requests with the Python `requests` library, and effectively parsing JSON responses. The tutorial also covers using Pandas for exploratory data analysis on the fetched data and leveraging a \\'Stop Lookup\\' API to identify specific stop IDs. This is a crucial skill set for any data engineer dealing with external data sources!'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()[\"bot_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d87e3eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'parts': [{'content': '\\n        You are an expert Youtuber in Data Engineering and AI Engineering.\\n        Always start with the greeting; \"Ro Bt my friend!\"\\n        Always use the retrieved knowledge of the Youtube transcripts from your tool to answer the question. \\n        Always point to the video title you are referring to.\\n        But do add more flavor from your expertise about the subject, keep it brief.\\n        ',\n",
       "     'timestamp': '2025-12-11T11:56:00.054647+00:00',\n",
       "     'dynamic_ref': None,\n",
       "     'part_kind': 'system-prompt'},\n",
       "    {'content': \"video about api's\",\n",
       "     'timestamp': '2025-12-11T11:56:00.054689+00:00',\n",
       "     'part_kind': 'user-prompt'}],\n",
       "   'instructions': None,\n",
       "   'kind': 'request',\n",
       "   'run_id': 'a7463f71-a619-4ef1-8318-7903d9ff31d9',\n",
       "   'metadata': None},\n",
       "  {'parts': [{'tool_name': 'retrieve_matching_video',\n",
       "     'args': {'query': \"video about api's\"},\n",
       "     'tool_call_id': 'pyd_ai_4957e8b1f95440d384068ac74efb9e79',\n",
       "     'id': None,\n",
       "     'provider_details': {'thought_signature': 'CqMCAXLI2nyE97FhgQ2YaHW70dgAN+2GJy7UuD+E4DnVS6DTPtDyiBCqR6YFo7VjzgkYlzxT2OkD/RjabUEw9ca4R6b1QNwgtq15YettZbq0ZMv1uAsnZppPiRfmMneweLGlIOoHR12pJvWEgLtyIOrwufymtlyPaP7zpD3m1Js121si/DJ1GotZ46KRIP7WSenV8/HMJeHvtpT6RfdU+82/YEEtJdSG0fTxFqTpfu8sHomFAeojzNSR/m4jkuKS4uhoew5HNo9Ijxpm64+hExTO7EtcipkaIZlorgTOnpI/oP5t48zRcEaqToSu1fKzWAevTGNQ0oliAnm/QPTt+RFC8EVxtweNNfkLllfIfng6rpB/U1TGQS/hI/iRIg1YRqDWGI+M'},\n",
       "     'part_kind': 'tool-call'}],\n",
       "   'usage': {'input_tokens': 225,\n",
       "    'cache_write_tokens': 0,\n",
       "    'cache_read_tokens': 0,\n",
       "    'output_tokens': 82,\n",
       "    'input_audio_tokens': 0,\n",
       "    'cache_audio_read_tokens': 0,\n",
       "    'output_audio_tokens': 0,\n",
       "    'details': {'thoughts_tokens': 61, 'text_prompt_tokens': 225}},\n",
       "   'model_name': 'gemini-2.5-flash',\n",
       "   'timestamp': '2025-12-11T11:56:01.118610+00:00',\n",
       "   'kind': 'response',\n",
       "   'provider_name': 'google-gla',\n",
       "   'provider_details': {'finish_reason': 'STOP'},\n",
       "   'provider_response_id': 'UbE6aclKgKrE3w_au6rQBA',\n",
       "   'finish_reason': 'stop',\n",
       "   'run_id': 'a7463f71-a619-4ef1-8318-7903d9ff31d9',\n",
       "   'metadata': None},\n",
       "  {'parts': [{'tool_name': 'retrieve_matching_video',\n",
       "     'content': \"\\n        Video title: api trafiklab (1),\\n        Content: # API trafiklab\\n\\n[00:00:00] Hello and welcome to this video where we'll go into getting data from an API. And the API that we've chosen is Trafiklab. And from this API, you will be able to get data on public transport. \\n\\nIt's good to, understand a little bit about the data set so that you could, for example, monitor if there's delays in the trams or trains. So yes moving on, we'll go into the web browser directly now.\\n\\nSo here I'm in the web browser and I've gone into Trafiklab.\\n\\nse slash API. Let me move myself here.\\n\\nIn Traffic Lab SC slash api~~ we have ~~we have several APIs that we can work with. And~~ one, ~~the ones that we will pick are those that are in s robot. So here race robot stalled. It's tabella here. You can get the timetables for different stops.\\n\\nSo we'll go in and ~~see ~~see more details, how to work with this one. [00:01:00] And this re robot plan is used for ~~planning~~ planning your trip. For example, you want to travel ~~from Sweden to ~~from UBO to Stockholm, ~~for example. ~~Ubo to Malmo. You can find out. ~~The trips~~ which type of trains and buses there are and their stops, et cetera.\\n\\nSo this is quite interesting and it's an open API so that you can use it for free. The only thing you need to do is ~~to ~~to create an account and register ~~for ~~for these APIs to use. Firstly. ~~You, ~~if you scroll up here, there's Minna sidor or my pages. So clicking on this one we'll go in here and you can create an account for me, I will just log in with GitHub so that you can do if you have a GitHub.\\n\\nAnd here~~ I have ~~you should create your own projects. So basically I have a few projects, I have streaming data and I have this testing and there's also a sandbox here. So you should create a new project.[00:02:00] \\n\\nSo when creating a new project, you give it a name. I will give it a, for example, a travel planner, ~~for example, ~~and ~~you can have a homepage if ~~you can link to a homepage if you want, but if you don't, it's okay. You can choose what type of project it is. It's an educational project and open source repository if you have that.\\n\\nBut~~ unless you don't need, ~~you don't need to. ~~And ~~description is also good to have or it's mandatory because these are optional. Description learning. Let's see. Learning. Lab a p. Same.\\n\\nSo here ~~I have~~ I have the travel planner ~~and ~~and now you should get your API keys ~~and to get the ~~. It's basically like this. ~~You choose here~~ you choose which type of API you want. And the one we want to pick is a robot\\n\\nme see here. Race robot version 2. 1. And then you click add key to project and you will get an [00:03:00] API key. \\n\\nHere are the API keys. I won't go down to the API keys because I don't want to share them with you. Instead you should go down there and copy ~~that key~~ that specific key because we will use it ~~in order to get ~~in order to use this page~~ get the ~~APIs.\\n\\nSo moving on to when you have the key store it in a dot ENV file, I'll show you how that looks soon. Or actually we can go there directly. I'll go to Visual Studio Code. And here~~ in this~~ in this project, I'll open a new terminal and let's see what I will do. I will do touch dot ENV.\\n\\nSo that we get a dot ENV file and inside this dot ENV file, you should write API equals to your API key the ones that you've copied. So just copy and paste it here and then we'll go back to Visual Studio. And we'll go back to. Traffic [00:04:00] lab and inside of API keys or actually documentation.\\n\\nYou've got the documentation and you're going to API overview, right here, and we can go into this robot started stability, for example, click on this one and here there is a example on how you call this one. So you basically just copy this one. Departures and arrivals, right? So you copy this one in order ~~to ~~to get the data from this one.\\n\\nAnd, but then you need to create an if you're using Python, which we're using in this course, and in this lecture we will~~ we'll ~~use the request library and we will do a get request to this end point and using our API key. And also you can go down here to read a little bit more about different options and what they mean.\\n\\nSo I won't go through them instead I will leave it to you for you to read. But let's go back to Visual Studio Code now [00:05:00] and let's set up different things. So let me do this. I will create the virtual environment. So uvvnv source dot. So now I've activated my virtual environment and I will do uv pipinstall.\\n\\nWhat do I need? I need ipykernel, of course, because I will work with Jupyter Notebook. I also need pandas. And I also need And let me think, what do I need requests? I need yes, starting with this. I think not dot ENV of course. So Python dot ENV. One thing with env it is for so that you can store your secrets.\\n\\nI'll show you what that means soon. So let's create a Jupyter notebook file now. So touch\\n\\nlet me see touch [00:06:00] API, public transport, ipnb. Okay. And now we'll open this one.\\n\\nSo we'll do an EDA on public transport traffic lab API. And then I'll change this to my virtual environment.\\n\\nSo let's start with testing out our dot ENV. ~~So from dot, let me change this to Python and I'll increase it, making it a little bit bigger. ~~So from dot ENV import load dot ENV. And we need to import OS as well in order for us to get the environment variable and then we'll do import requests .\\n\\nAnd starting with our load. dnv, we can do like this. Start with load. dnv. In general, you need to have a path here. But~~ in, ~~when you're in Jupyter Notebook, you have the path is based on where ~~this ~~this file is so since e NV is a sibling [00:07:00] to this file and this Jupiter notebook, ~~then~~ then do ENV will be found.\\n\\nSo when we do low e nv and then we can do os get ENV, and we take the API, if we are going to nv, we can see that it's called, it's just called. I'll call it API key. And then I will do API key here. And if I run this one, we can see we get dot. That means that ~~we~~ the Jupyter Notebook finds this dot DNV.\\n\\nOkay, great. So now I'll just pause the video and I'll put in my real key. So remember, the real key can be found ~~in ~~in strategic lab where you're logged in.\\n\\nI've added my real key and of course I won't show that to you. It's important that you add do ENV ~~to your ~~to your.gi nor file. If it isn't there already, so that is to [00:08:00] make sure that it's not tracked by Git and that you don't accidentally push it to a public GitHub repository.\\n\\nSo this is in order for us to so because we don't want to write out the API key here. Directly because when I push it~~ you ~~then people will see it ~~in my directory, ~~in my repository and can use my API key. So secrets store it in DNV and load it using Load d nv. Okay, so then this one, I can just call it API Key equals to this.\\n\\nSo if I run this one it, it is stored in API key, but~~ I ~~I don't write it out so that you can't see what it is. However, I will use it later on. So now we'll go into Trafiklab. So here in Trafiklab, let me see. So in traffic lab we have if we go into our ~~this robot~~ [00:09:00] this robot route planner, you can start here and you can see this example call.\\n\\nLet's copy this one. So it says. This example called ~~receive ~~retrieves all routes from Stockholm Central Station ~~seven~~ this ID to Malm Central Station, another ID. So I just copy this one and I go back to my Visual Studio code and I will call URL equals to this, make it into a string and make it into an F string.\\n\\nAnd then I will also make this API key into a variable so that I can use this. API key inside of this URL. Okay so since we have, we can read it out here. So api. resrobot. se version 2. 1 slash trip. So ~~this is the end, so it's~~ it's the API. We query, we're using the format. This is an [00:10:00] option. The option is a format which is JSON.\\n\\nAnd another option, origin ID equals to this ID. And dest ID is destination ID is this ID here. And then we have pass list equals true and show passing points equals true. Actually, I'm not sure what both of them are. ~~It's ~~it's listed in the documentation in the web page, which you can read about.\\n\\nAnd then most important, very important, is that we have the access ID, which is our pass list. API key, right? So that is very important. And we get the API key from our dnv. So that is how everything is connected. So now we have our URL. So this is an endpoint for us to retrieve data. So in order for us to get the data we need to do requests dot get, and basically we just put in the URL.\\n\\nAnd we call [00:11:00] this response equals to this response. And I run this one response 401. Why is that? Let me pause and I will pause and debug this.\\n\\nOkay, I found a problem. First of all, I wrote response. txt to see~~ to see what~~ what text we get. And we get an error code, which says API auth, error text access denied. Okay, then I thought based on this, what could be the problem? Maybe the API key is wrong. So what did, ~~I just, ~~I typed out API key and saw what I get.\\n\\nDot dot. How strange, even if I re ran this one, I got API key. Because this is already loaded, right? That is how it works in Jupyter Notebook. When it loads one time, it won't load again. So this is important if you have~~ if you ~~started with something else than ~~your API, ~~your real API key. Just do restart.\\n\\n~~Restart this one, ~~and now I will [00:12:00] remove this cell here. And if I run this one, now it should work. Yes, now it works. We can see there's a response. txt, and we have Stockholm Central Station and a lot of things here. So instead of getting it as a text, I want to get it as a JSON object. ~~So as a JSON, ~~so JSON object is basically in Python is represented as a dictionary.\\n\\nSo you have a dictionary of a list and you have a lot of other things. So in dictionaries, a very important thing what I usually do when I start working with API where I get JSON data is that I usually Try to explore this API, explore this dictionary. So starting with this, let's continue.\\n\\nWe can do like this. Let's see. Response. json we can get let me see. Response. json, we can call it results,[00:13:00] \\n\\nresponse. json, result, and we do result. keys, and we can see what type of keys we have. So we have trip, we have result status, and technical messages, server version, et cetera. So there's a lot of things here. And actually in my Jupyter notebook~~ in the. ~~In the lecture note, you can see that I've explored most of them, I think.\\n\\nHowever, ~~you should also ~~you should also check them out. What we can do is like this. Since it's a dictionary, we can take out the trip here. And we can see that it's a list. It starts with brackets here. If it's a list, we can do like this. We can do length of this. And we can see seven.\\n\\nOkay, there was seven here. We could do a result of result status and see what that is. Okay. ~~Some time diff ~~some kind of metadata. I'm not sure what this, ~~what it ~~is, but ~~you should, ~~you can read in the [00:14:00] documentation in case you wonder. We can continue here technical messages, and see what we get here.\\n\\nOkay, so technical messages. We get ~~some, ~~something that I don't understand either. Let's continue going on down here and we'll take ~~serve ~~server version. Probably I can understand what that is. Dialect version plan R T S. I think those are not so relevant for us. So we will continue with the trip.\\n\\nSo results of trip. So you can see here we have it's a list and now it's seven items, right? So what we can do with this is that we could ~~loop through it. So if it's a list, we can ~~loop through it. We can loop through the list. And actually in the lecture notes, I have created A function~~ of this ~~of the get request, basically.\\n\\nSo that is a little bit [00:15:00] more elaborate and ~~you can~~ you can choose it to use. ~~And we can ~~however, here ~~I will I will not write, or ~~I can write out the function, actually. Because we will use it later on. Let's do that. Let's go into the function. I will create a function of it. I will just copy from the lecture note and I will explain that.\\n\\nThis is what I did for the function. We can remove the API key as we had it earlier. So basically it's the same as before. We have a URL, however, the origin ID and destination ID I put it into as parameters so that you can send them in as arguments ~~in order ~~if you want to Choose other destinations and origins.\\n\\nNow, the first one is Stockholm and the other one is Malm, but I want to get ~~the ~~just the body later on. So then afterwards we do a try ~~because how come? ~~Because the response object, the request. get, it can fail, right? It can fail with different [00:16:00] exceptions. And if it has an exception we also do response.\\n\\nraise for status. So in case It'll raise an HTP error if it occurred. ~~Four, 400 x four xx and five xx. ~~So if you get status code 400 something, 500 something, then it's some kind of HTTP error. And that is what ~~I~~ we're catching here with the accept. So this one. Result equals getTrips and we can get result.\\n\\nkeys. And this is basically the same ~~as~~ as I showed before. So now we have the trip, we get result of trip, right? So we can call this, let me see, we can call this we can call, for example exampleTrip equals to this one, and I will take the zero of it. Example trip of, so if I do example trip now, you can see that we get the first one.\\n\\nSo origin [00:17:00] is in Stockholm and destination is in Gteborg, central Stockholm. Interesting. Yeah, I changed also here, this is another ID than the one I used before. So this one, this idea is for Gteborg, but how do we know which idea corresponds to which city or which stop? That, that will come back to later on in in the next section here, but we have Gteborg and Stockholm.\\n\\nSo let's continue. We can we can figure out a little bit more things here. Here we can go into we can go in to example trip of for example we can go into distinct origin, and we can see that we get Stockholm and and it has these keys and these values. We can continue copy this one and go into example trip of destination.\\n\\nAnd we can see that, okay, Gteborg Centralstation, et cetera, cool. [00:18:00] And you can explore more things here, but something I thought was quite interesting was so if you go into exampletrip.\\n\\n~~key, exampletrip, ~~you can run this one. And you can see here, origin, destination, and we have service days. Actually, we can do exampleTrip. keys to find out what we have. So origin, destination, service days, legList is quite interesting. So I'll do legList. And this one, here we can see a lot of information. We have origin, we have destination.\\n\\nSo we have several destinations, it seems. ~~So it seems to be, ~~so we have Stockholm here, and then we have Karlstad, so we can continue to find out different types of stops. ~~Leg list, and then we take out leg. ~~[00:19:00] Actually, ~~this ~~these names, I'm not sure what they stand for, but~~ they are in, ~~this is how they coded the response object.\\n\\nSo we get the list here. This is quite interesting. So let's do length of this list. I want to see how many there are here. Okay. Two. I'll copy this one.\\n\\nOkay. For example, I will pick the zero\\n\\nand in the zero, we have origin destination. I can do dot he's. And we can see we have origin, destination, journey status, stop. It's quite interesting. So I'll continue, copy this one. I'll go [00:20:00] into stops. And we can see, okay, stops. We have some key called stop. And then there's a list here. Okay, so we'll pick that one, stop.\\n\\nAnd we can see there's a list. Stockholm, Katrineholm, Hallsberg. Okay, see, ~~this is, ~~this requires some domain knowledge. ~~If you're ~~if you have traveled trains between Stockholm and Gteborg. These are common stations that exist there. So these are ~~the common stations or common, ~~the common stops, ~~though.~~\\n\\nOkay, so this is quite interesting. So we could continue here and we could actually call for example, these are different stops, right? We could call it example stops, example, stops like this. And then I will loop through this one. So I will do like this. For stop [00:21:00] in example stops, and I can do stop dot get name.\\n\\nSo basically get the same as using bracket notation. However, it won't return an error if the key is missing. Instead, it will give you none if the key is missing. So colon stop dot get for example, I will get the arrival time\\n\\nor departure arrival time. Yeah, I could take departure time as well. Okay, let's see. Yeah, I need curly braces because I want to make a dictionary here. So basically I'm doing a list comprehension of the dictionary. So here we can see, okay, we started with Stockholm Central Station. We go into Katrineholm, Hallsberg, Degerfors, Kristinehamn and Karlstad.\\n\\n~~Cool. ~~Cool. Maybe the other section, [00:22:00] because the length of these stops were two, right? And this ~~example stop that we, ~~example stops that we have, maybe this is half of the journey. I'm not sure this is worth finding out. Okay. But how did we get the body ~~as~~ as the stop as this as the ID, right?\\n\\nSo this, we need to use ~~some, ~~another API. Called ResRobotStopLookup, so I will go ~~into here, ~~into the browser, and we can see in the browser, we have a stop lookup, and ~~the stop lookup, ~~it will basically, ~~so ~~you have here, this is the API, you have location. name, question mark, input equals just a body, And format equals ~~Jason.~~\\n\\nAnd if you do ~~it, ~~the bar question mark, then you will, it's a ~~fussy ~~search so that it will match something that is similar to it. So basically here, you can see ~~what they said, like ~~the input ~~here, input as a, ~~as the option and [00:23:00] the search string, append the question mark for ~~fussy ~~search, that means we will find something ~~if we will find ~~for example, if we take.\\n\\n~~If we just take, ~~without the question mark, we'll only get Gteborg here. This is the data we get. We get the ID, external ID, name, ~~and ~~longitude, latitude, etc. But with Fuzzy Search, ~~we'll get everything that, ~~we'll get things that are similar. ~~So we get Gteborg etc. ~~So everything with Gteborg is matched here.\\n\\nOkay, cool. But then we find the external ID and then you use the external ID to put it into ~~your ~~your travel planner or your route planner or your ~~time ~~timetables. So moving back to Visual Studio Code.\\n\\nOkay so let's go into the stop lookup API. Here, we have stop look up API. We use this to find the ID. I will copy the URL. And basically I can copy all of this [00:24:00] here. I'll change this to Python. And then, okay, if you look into What we did here. So location is just the body. I have an F string so that I search and get the body.\\n\\nAnd this is a, an exact search. Now we don't have a question Mark and we have a API key and we have a result basically. So if I run this one,\\n\\nwe get the stop location or cord location,\\n\\nand we can do results let's see results of. Stop stop location or cord location. And I run this one and we can see here we have stop location\\n\\nand you can see name is yet the body\\n\\nand we can see, let's see, this is a list, right? So I can [00:25:00] do length of this list and it it contains 10 values. So basically, okay, we have 10 10 stops. Okay, so I will do result of, actually I will call this one, I'll remove this one like here, and I'll do stop locations equals to this, give it a variable, stop locations, and then I'll do stop locations, I'll run this one.\\n\\nSo we have for example, zero, stopLocation zero, and we could take stopLocation zero of stopLocation, and we can dot, take dot keys, and we can see the keys here. Okay, so it has an external ID, and it has a name. That is interesting. So how, what if I do like this? I copy this one, and I take out [00:26:00] name.\\n\\nCool. And if I copied this one and ~~I take out ~~I take out X ID, external ID, and we get, The external ID. So perfect. So this is how I got the ID for in order to put it into my route planner before. But if we have several, we want to pick the one that fits the best for us. Then basically ~~just ~~just do like this.\\n\\nWe can loop through this. Let's do four, stop location, in stop locations. Remember that stop locations is a list. Stop locations is a list of ten values. And inside of stop locations there is, so when I look through it, I will get This value and then I will get 0, 1, 2, 3, 4, up to 10 or up to nine.\\n\\nSo [00:27:00] here, this is a for loop and I want to have ~~stop location or stop equals ~~stop location or stop location, right?\\n\\nAnd why do I do that? We can see that I did it here because that is how it was structured. So I needed to take this. guy and do get the stop location. And from the stop location, I need to find the name, right? So then I can print the stop of name and stop of external ID. So here you can see, here are all the IDs for Gteborg.\\n\\nSo basically I can also do, I will do a little bit better formatting here. So print fString, stop,[00:28:00] \\n\\nstop like this, and it should have a left alignment of 50 character wide field. This is what it means using fString formatting. And then afterwards, after these 50 characters, I want to have My next string. So my next string is external ID. So then I get stop here and I get the external ID here. And then I could left align these also.\\n\\nSo that it comes into the external ID. So what I do is here stop. I need to do similar here. Like this, and I need to do it into F string like this,\\n\\nlike this. If I run this [00:29:00] one, let's see. Yes, nothing happens, but if I do colon 50 character wide, and this means left alignment, other side means right alignment. So then, perfectly, now it's now it's easy for me to find out ~~which~~ which one I want. So if I want to have, for example Volkswagen, then I just pick this ID here.\\n\\nOkay, great. And, yes, I've actually in my lecture note you should look into that. I have put it into a function which works. Which you can use for finding other locations that is actually quite good to have us as well. So I will copy that one. So this is from my lecture note, access ID from location.\\n\\nSo you just type in the location and it will find bind it for you. And basically it's the same idea as before, however, ~~one important, ~~some important things here is that I use [00:30:00] so this is quite interesting. Okay, so this you have seen before you get the response object. And you get it as a JSON, you put it into try because there can be exceptions.\\n\\nThen you do this for loop. And here is one important part, is that stopData equals to next of iter of stop. values.\\n\\n\\n\\nThat is the logic. And then it has an except for for some errors. But with this one, you can just use this function immediately. So access ID from location. We can, for example, get Malm, and we're doing a fuzzy search so that we have here, we see Malm, and you can get the external ID, Malm, here, another ID.\\n\\n~~You can~~ you can, for example, find a very small city here called Unsala. And you can see, yeah here's what's found in [00:31:00] Onsala. Actually, there's more stops in Onsala, but they don't have external IDs. And that's why ~~so ~~you can actually test it out without this if statement here. And ~~you will see ~~you will see more stations that corresponds to Unsala but~~ that, ~~that's why ~~I use this ~~I use this one in order for me to stop so that I can get the external ID because without the external ID, I cannot use it further anyway.\\n\\nAnd also ~~I will for example, ~~I can find something else. This interesting is another small city. And you can see, yeah, there's a lot here. Okay. ~~But ~~perfect. Now ~~we have~~ we have this and we can move on to another API. We can move on to time tables. So in time tables, we go into this robot and we have time tables here.\\n\\nAnd similarly, just copy this one here for departures and one for arrival. [00:32:00] You can pick the ones you want. ~~And let me. ~~Let me go up a little bit and find will actually go and copy. I ~~will ~~copy from my lecture note here. So this is for Korsvagen stop ID, because if I go up here, I have Gteborg Korsvagen is this ID.\\n\\nI will copy this one.\\n\\nAnd I go in here and store it. So this is the stop ID. I use this one to get the results I want. ~~And so you see it's another API endpoint. ~~And now actually I won't in this part, I won't put it into function, but~~ it's a, ~~it is good practice for you to put it into function ~~and ~~and do that and I will leave that for you to do.\\n\\nInstead I will just pick out some, I will show you using a data frame. Now ~~the ~~import pandas as pd, [00:33:00] we could do like this. If we write out results. Results is a JSON object, right? That looks like this departure and it has a lot of other things. However, I'll just pick out the departure.\\n\\nI'll actually throw this away because it will clutter my notebook. ~~When ~~otherwise I will do ~~the~~ the PD dot data frame of results of departure. That is where my data is. So df equals to this, df timetable, df timetable ~~dot~~ dot head, right? Head, like this, and you can see okay, so this is quite neat to work with.\\n\\nIf you have a data frame, it's much neater than working ~~with~~ with the ~~Jason ~~objects directly.[00:34:00] \\n\\nSo before we unnested the ~~Jason ~~objects and we looped through to get the things that we wanted, but now you can use the power of pandas and your panda skills in order to data process this. So basically you could do like this. dftimetable. columns for example. And we can see what ~~the ~~columns we have.\\n\\n~~We could do dftimetable ~~We can pick out ~~we can, ~~for example, clean it so that for example, we want to pick out what do we want? We want name and we can see, yeah, ~~this is, ~~these are the names we could pick out. What do we want more? We could pick out the stop and we have all the stops here.\\n\\nWe could pick out longitude, latitude, which you could use to draw in a map, dots in a map if you want. And see if you can map out the body direction [00:35:00] here, you can see where the directions are for the ~~trams on ~~trams and buses, we could ~~do ~~also ~~interesting in ~~which date we are using.\\n\\nSo date okay. Six is today and we can see the time and yeah, I just accessed the data. So you can see that Yeah. Okay. Here is a time in around one hour, one hour time, and you can see that we have, okay, ~~one~~ 116 ~~buses and tra ~~buses and trams included~~ that ~~that the departures ~~from ~~from Kosh wagon.\\n\\nOkay. So we could call this df timetable clean, for example. And then we could do DF timetable clean. And we could find out for example, name dot value counts. And we can see, yes, ~~these are the unique ones in ~~these are the unique buses and trams ~~in in ~~this station at this~~ station.~~\\n\\nParticular time frame from ~~from seven, ~~1911 to [00:36:00] 2011. And you can see, yeah, these are the most common ones and yes, ~~they~~ you have uncommon ones ~~are ~~express bus. They are ~~come, they're flying or they're. ~~Going further away and fleet transfer means flight transfer. So they're also more uncommon?\\n\\nYes. Okay. And with this~~ you, ~~you can do more exploratory data analysis, but I will leave that for you. So with this, I would like to thank you for watching this video and see you in the next one. Bye.\\n\\n,\\n        Content: https://www.youtube.com/@AIgineer,\\n    \",\n",
       "     'tool_call_id': 'pyd_ai_4957e8b1f95440d384068ac74efb9e79',\n",
       "     'metadata': None,\n",
       "     'timestamp': '2025-12-11T11:56:02.456110+00:00',\n",
       "     'part_kind': 'tool-return'}],\n",
       "   'instructions': None,\n",
       "   'kind': 'request',\n",
       "   'run_id': 'a7463f71-a619-4ef1-8318-7903d9ff31d9',\n",
       "   'metadata': None},\n",
       "  {'parts': [{'tool_name': 'final_result',\n",
       "     'args': {'video_title': 'api trafiklab (1)',\n",
       "      'answer': 'Ro Bt my friend!I found a video titled \"api trafiklab (1)\" that dives into getting data from APIs, specifically using the Trafiklab API for public transport information. The video covers essential steps for any aspiring data engineer working with external services. It shows you how to set up an account, obtain and securely manage API keys (a crucial practice, always keep those secrets out of your public repositories!), and then make `GET` requests using Python\\'s `requests` library. You\\'ll also learn how to parse and explore the JSON responses, and even integrate with pandas DataFrames for easier data manipulation. Understanding API documentation is key to unlocking the full potential of any API, and this video gives a great practical example of how to navigate one.',\n",
       "      'video_link': 'https://www.youtube.com/watch?v=api_trafiklab_1'},\n",
       "     'tool_call_id': 'pyd_ai_4ffca2e05e3f423ea71ecb1db20f9438',\n",
       "     'id': None,\n",
       "     'provider_details': {'thought_signature': 'Cu4JAXLI2nxnRQypVcrKFoY5N+DpdT5RXjhQ73F/6jWUFZ8FyHskrhW4J15s2/rSC/+DIlHY6mZsvUOSGtge68jSQqD4AcCLLgTnO5IsibuhHQPnednlRtwsrbcyCM+3XkK/zNrTBKKDAB+orAvr47s5cYjOF+hZ7JXdEFDu04CJiuIXKUUhjDNjzbNOwolQUlPLCb1yN6CeoHRlhEPqQD3t7wmweCyoGXxoHfVggBNPJlC3czQ/y6nXdPrIYXNRN9FD8/zk/ab2xuoYzGUcYv1T6TJF6dIwN1jEDb1ahfi9BSs/mJZPFv61mGPNz2h19ALewjkFR/WGaSG80r6ZZnwZVPUb7oL+95V/my1AZP5GxaD+FLN8Ui8O0xrDkwytXiKzraP6+bioeiVvTJ5NOioAoh947/2l9jF33lP/PpS4mPYSWj4NUMKgV1H88RKOMDFKliR7dNhFM6qY3LNvjiPNQNWMuj29jTLf9NkttU1hJ0VS9PL3GLEvN6w3DI+tJqTdHReAhupFQP6YuA11jzyXsOIKsg2VXCNOflWBaGaciYPHgzKWXrQwLwzXfVn7Bxcg1snNxKMM0KkfiRefOSbiEzw5hOWtGWkU9eBb51zDZea8PLBjNTlSRCNPF54+oS6KmFI8rh7eMt9jgCwk7n1Nwdh9ewiJGz9jkgjLjpzYCHwki3217IU/Pndvc6JR9r0IAD6bitRFFK3MBMftfbaLx4DS8cDXBL8Rzd7/Mp9mLankMd/AIvGM79ohf2fptma7cP59cu38KE+5sRI5bXX6eepn1YnVH7TBi3xUPn5G602GcYfbaSoSlFyMH4O9SzXx/wpMmTQPms/Xym7+KHF2T7gNHwwombpZblR6THnE2g+BOvs7p3dcVh66QrfDlaWxSP6cnD89jmKTN5ZdoU7DzPer19hDlx7TshXVAqWUxnzXAT+La2DYBmUt3rBtJxYuJiCtScoTGFNI4O1xlPIUQboB6YCJiO1TkQZZbiMp5/xMuS8YgTsUiF0VzzEOck3hcH4yQ3uMynZUmozH85+dANzYienWyLNXCCi4UK2G575elVxnaI+X5idEEP0yj4eT7OeWRg6DIm/e8auLvknyMepIeGrGuhIBKKmu1XLQ8RRRmpZjDz2UPd06AXbTytYFgJLZe6miFSFDOLsJDbhr6a5a4m70cMdKgFFrwwz71yPIJpyq0uLve12y5V95iQBAuzvQeDWvhAzeArqF4ds9rU3Ie8mLWEza1ZjOtxvhCx0bAIUFko3AbzDtCA4k888agUvWvsGv5PkZE9tI/E0DOs3UMba+TWcJHQ/ltgQ+i9k2X28bv0MPLjzug2Ctxpj06rylgkZo7ZEj0If5NijkwLZt4HkRKXeTep+9OrlTW6/h3jblYJPAiyD8ayi7h/xCQ5L4TYgh1HSKtNAJUFIfKO47O2x8aUy0532nxhCMZC6qo/OvUi7nwk+8ej2DhqAOlF4rgQh6p9ZthIoPjxlrs/BHHiDG2b89qmGGEoyLaBpUJC3dzP3aaqe/ovBRdg/L5vGU6D2ACAA+plAipvEyesLvFMvt+PPX3Kka023c+GiPf9BpkZjDbQWtg0bNVqrQpeAmHiZNchkp+vv1JnHk98v3kPI2m4VrJD0St5T0PJchpYKYSxg2n08UQLetbPwSs8MANlB0ys/1BC4Wi/A='},\n",
       "     'part_kind': 'tool-call'}],\n",
       "   'usage': {'input_tokens': 7804,\n",
       "    'cache_write_tokens': 0,\n",
       "    'cache_read_tokens': 0,\n",
       "    'output_tokens': 475,\n",
       "    'input_audio_tokens': 0,\n",
       "    'cache_audio_read_tokens': 0,\n",
       "    'output_audio_tokens': 0,\n",
       "    'details': {'thoughts_tokens': 271, 'text_prompt_tokens': 7804}},\n",
       "   'model_name': 'gemini-2.5-flash',\n",
       "   'timestamp': '2025-12-11T11:56:05.594521+00:00',\n",
       "   'kind': 'response',\n",
       "   'provider_name': 'google-gla',\n",
       "   'provider_details': {'finish_reason': 'STOP'},\n",
       "   'provider_response_id': 'VbE6aZ-jHduFxs0PjrOAqQM',\n",
       "   'finish_reason': 'stop',\n",
       "   'run_id': 'a7463f71-a619-4ef1-8318-7903d9ff31d9',\n",
       "   'metadata': None},\n",
       "  {'parts': [{'tool_name': 'final_result',\n",
       "     'content': 'Final result processed.',\n",
       "     'tool_call_id': 'pyd_ai_4ffca2e05e3f423ea71ecb1db20f9438',\n",
       "     'metadata': None,\n",
       "     'timestamp': '2025-12-11T11:56:05.595647+00:00',\n",
       "     'part_kind': 'tool-return'}],\n",
       "   'instructions': None,\n",
       "   'kind': 'request',\n",
       "   'run_id': 'a7463f71-a619-4ef1-8318-7903d9ff31d9',\n",
       "   'metadata': None}]]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd267f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_history = []\n",
    "for turn in response.json()[\"history\"]:\n",
    "    for part in turn[\"parts\"]:\n",
    "        # Check if both keys exist in the dictionary\n",
    "        if \"content\" in part and \"part_kind\" in part:\n",
    "            content = part[\"content\"]\n",
    "            part_kind = part[\"part_kind\"]\n",
    "            if content:\n",
    "                readable_history.append({\n",
    "                    \"part_kind\" : part_kind,\n",
    "                    \"content\" : content\n",
    "                })\n",
    "readable_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "bce54e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = \"http://127.0.0.1:8000/rag/history\"\n",
    "#url = \"http://127.0.0.1:7071/rag/history\"\n",
    "the_response = requests.get(url=url)\n",
    "the_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "be0152ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'part_kind': 'system-prompt',\n",
       "  'content': '\\n        You are an expert Youtuber in Data Engineering and AI Engineering.\\n        Always start with the greeting; \"Ro Bt my friend!\"\\n        Always use the retrieved knowledge of the Youtube transcripts from your tool to answer the question. \\n        Always point to the video title you are referring to.\\n        But do add more flavor from your expertise about the subject, keep it brief.\\n        '},\n",
       " {'part_kind': 'user-prompt', 'content': \"video about api's\"},\n",
       " {'part_kind': 'tool-return',\n",
       "  'content': \"\\n        Video title: api trafiklab (1),\\n        Content: # API trafiklab\\n\\n[00:00:00] Hello and welcome to this video where we'll go into getting data from an API. And the API that we've chosen is Trafiklab. And from this API, you will be able to get data on public transport. \\n\\nIt's good to, understand a little bit about the data set so that you could, for example, monitor if there's delays in the trams or trains. So yes moving on, we'll go into the web browser directly now.\\n\\nSo here I'm in the web browser and I've gone into Trafiklab.\\n\\nse slash API. Let me move myself here.\\n\\nIn Traffic Lab SC slash api~~ we have ~~we have several APIs that we can work with. And~~ one, ~~the ones that we will pick are those that are in s robot. So here race robot stalled. It's tabella here. You can get the timetables for different stops.\\n\\nSo we'll go in and ~~see ~~see more details, how to work with this one. [00:01:00] And this re robot plan is used for ~~planning~~ planning your trip. For example, you want to travel ~~from Sweden to ~~from UBO to Stockholm, ~~for example. ~~Ubo to Malmo. You can find out. ~~The trips~~ which type of trains and buses there are and their stops, et cetera.\\n\\nSo this is quite interesting and it's an open API so that you can use it for free. The only thing you need to do is ~~to ~~to create an account and register ~~for ~~for these APIs to use. Firstly. ~~You, ~~if you scroll up here, there's Minna sidor or my pages. So clicking on this one we'll go in here and you can create an account for me, I will just log in with GitHub so that you can do if you have a GitHub.\\n\\nAnd here~~ I have ~~you should create your own projects. So basically I have a few projects, I have streaming data and I have this testing and there's also a sandbox here. So you should create a new project.[00:02:00] \\n\\nSo when creating a new project, you give it a name. I will give it a, for example, a travel planner, ~~for example, ~~and ~~you can have a homepage if ~~you can link to a homepage if you want, but if you don't, it's okay. You can choose what type of project it is. It's an educational project and open source repository if you have that.\\n\\nBut~~ unless you don't need, ~~you don't need to. ~~And ~~description is also good to have or it's mandatory because these are optional. Description learning. Let's see. Learning. Lab a p. Same.\\n\\nSo here ~~I have~~ I have the travel planner ~~and ~~and now you should get your API keys ~~and to get the ~~. It's basically like this. ~~You choose here~~ you choose which type of API you want. And the one we want to pick is a robot\\n\\nme see here. Race robot version 2. 1. And then you click add key to project and you will get an [00:03:00] API key. \\n\\nHere are the API keys. I won't go down to the API keys because I don't want to share them with you. Instead you should go down there and copy ~~that key~~ that specific key because we will use it ~~in order to get ~~in order to use this page~~ get the ~~APIs.\\n\\nSo moving on to when you have the key store it in a dot ENV file, I'll show you how that looks soon. Or actually we can go there directly. I'll go to Visual Studio Code. And here~~ in this~~ in this project, I'll open a new terminal and let's see what I will do. I will do touch dot ENV.\\n\\nSo that we get a dot ENV file and inside this dot ENV file, you should write API equals to your API key the ones that you've copied. So just copy and paste it here and then we'll go back to Visual Studio. And we'll go back to. Traffic [00:04:00] lab and inside of API keys or actually documentation.\\n\\nYou've got the documentation and you're going to API overview, right here, and we can go into this robot started stability, for example, click on this one and here there is a example on how you call this one. So you basically just copy this one. Departures and arrivals, right? So you copy this one in order ~~to ~~to get the data from this one.\\n\\nAnd, but then you need to create an if you're using Python, which we're using in this course, and in this lecture we will~~ we'll ~~use the request library and we will do a get request to this end point and using our API key. And also you can go down here to read a little bit more about different options and what they mean.\\n\\nSo I won't go through them instead I will leave it to you for you to read. But let's go back to Visual Studio Code now [00:05:00] and let's set up different things. So let me do this. I will create the virtual environment. So uvvnv source dot. So now I've activated my virtual environment and I will do uv pipinstall.\\n\\nWhat do I need? I need ipykernel, of course, because I will work with Jupyter Notebook. I also need pandas. And I also need And let me think, what do I need requests? I need yes, starting with this. I think not dot ENV of course. So Python dot ENV. One thing with env it is for so that you can store your secrets.\\n\\nI'll show you what that means soon. So let's create a Jupyter notebook file now. So touch\\n\\nlet me see touch [00:06:00] API, public transport, ipnb. Okay. And now we'll open this one.\\n\\nSo we'll do an EDA on public transport traffic lab API. And then I'll change this to my virtual environment.\\n\\nSo let's start with testing out our dot ENV. ~~So from dot, let me change this to Python and I'll increase it, making it a little bit bigger. ~~So from dot ENV import load dot ENV. And we need to import OS as well in order for us to get the environment variable and then we'll do import requests .\\n\\nAnd starting with our load. dnv, we can do like this. Start with load. dnv. In general, you need to have a path here. But~~ in, ~~when you're in Jupyter Notebook, you have the path is based on where ~~this ~~this file is so since e NV is a sibling [00:07:00] to this file and this Jupiter notebook, ~~then~~ then do ENV will be found.\\n\\nSo when we do low e nv and then we can do os get ENV, and we take the API, if we are going to nv, we can see that it's called, it's just called. I'll call it API key. And then I will do API key here. And if I run this one, we can see we get dot. That means that ~~we~~ the Jupyter Notebook finds this dot DNV.\\n\\nOkay, great. So now I'll just pause the video and I'll put in my real key. So remember, the real key can be found ~~in ~~in strategic lab where you're logged in.\\n\\nI've added my real key and of course I won't show that to you. It's important that you add do ENV ~~to your ~~to your.gi nor file. If it isn't there already, so that is to [00:08:00] make sure that it's not tracked by Git and that you don't accidentally push it to a public GitHub repository.\\n\\nSo this is in order for us to so because we don't want to write out the API key here. Directly because when I push it~~ you ~~then people will see it ~~in my directory, ~~in my repository and can use my API key. So secrets store it in DNV and load it using Load d nv. Okay, so then this one, I can just call it API Key equals to this.\\n\\nSo if I run this one it, it is stored in API key, but~~ I ~~I don't write it out so that you can't see what it is. However, I will use it later on. So now we'll go into Trafiklab. So here in Trafiklab, let me see. So in traffic lab we have if we go into our ~~this robot~~ [00:09:00] this robot route planner, you can start here and you can see this example call.\\n\\nLet's copy this one. So it says. This example called ~~receive ~~retrieves all routes from Stockholm Central Station ~~seven~~ this ID to Malm Central Station, another ID. So I just copy this one and I go back to my Visual Studio code and I will call URL equals to this, make it into a string and make it into an F string.\\n\\nAnd then I will also make this API key into a variable so that I can use this. API key inside of this URL. Okay so since we have, we can read it out here. So api. resrobot. se version 2. 1 slash trip. So ~~this is the end, so it's~~ it's the API. We query, we're using the format. This is an [00:10:00] option. The option is a format which is JSON.\\n\\nAnd another option, origin ID equals to this ID. And dest ID is destination ID is this ID here. And then we have pass list equals true and show passing points equals true. Actually, I'm not sure what both of them are. ~~It's ~~it's listed in the documentation in the web page, which you can read about.\\n\\nAnd then most important, very important, is that we have the access ID, which is our pass list. API key, right? So that is very important. And we get the API key from our dnv. So that is how everything is connected. So now we have our URL. So this is an endpoint for us to retrieve data. So in order for us to get the data we need to do requests dot get, and basically we just put in the URL.\\n\\nAnd we call [00:11:00] this response equals to this response. And I run this one response 401. Why is that? Let me pause and I will pause and debug this.\\n\\nOkay, I found a problem. First of all, I wrote response. txt to see~~ to see what~~ what text we get. And we get an error code, which says API auth, error text access denied. Okay, then I thought based on this, what could be the problem? Maybe the API key is wrong. So what did, ~~I just, ~~I typed out API key and saw what I get.\\n\\nDot dot. How strange, even if I re ran this one, I got API key. Because this is already loaded, right? That is how it works in Jupyter Notebook. When it loads one time, it won't load again. So this is important if you have~~ if you ~~started with something else than ~~your API, ~~your real API key. Just do restart.\\n\\n~~Restart this one, ~~and now I will [00:12:00] remove this cell here. And if I run this one, now it should work. Yes, now it works. We can see there's a response. txt, and we have Stockholm Central Station and a lot of things here. So instead of getting it as a text, I want to get it as a JSON object. ~~So as a JSON, ~~so JSON object is basically in Python is represented as a dictionary.\\n\\nSo you have a dictionary of a list and you have a lot of other things. So in dictionaries, a very important thing what I usually do when I start working with API where I get JSON data is that I usually Try to explore this API, explore this dictionary. So starting with this, let's continue.\\n\\nWe can do like this. Let's see. Response. json we can get let me see. Response. json, we can call it results,[00:13:00] \\n\\nresponse. json, result, and we do result. keys, and we can see what type of keys we have. So we have trip, we have result status, and technical messages, server version, et cetera. So there's a lot of things here. And actually in my Jupyter notebook~~ in the. ~~In the lecture note, you can see that I've explored most of them, I think.\\n\\nHowever, ~~you should also ~~you should also check them out. What we can do is like this. Since it's a dictionary, we can take out the trip here. And we can see that it's a list. It starts with brackets here. If it's a list, we can do like this. We can do length of this. And we can see seven.\\n\\nOkay, there was seven here. We could do a result of result status and see what that is. Okay. ~~Some time diff ~~some kind of metadata. I'm not sure what this, ~~what it ~~is, but ~~you should, ~~you can read in the [00:14:00] documentation in case you wonder. We can continue here technical messages, and see what we get here.\\n\\nOkay, so technical messages. We get ~~some, ~~something that I don't understand either. Let's continue going on down here and we'll take ~~serve ~~server version. Probably I can understand what that is. Dialect version plan R T S. I think those are not so relevant for us. So we will continue with the trip.\\n\\nSo results of trip. So you can see here we have it's a list and now it's seven items, right? So what we can do with this is that we could ~~loop through it. So if it's a list, we can ~~loop through it. We can loop through the list. And actually in the lecture notes, I have created A function~~ of this ~~of the get request, basically.\\n\\nSo that is a little bit [00:15:00] more elaborate and ~~you can~~ you can choose it to use. ~~And we can ~~however, here ~~I will I will not write, or ~~I can write out the function, actually. Because we will use it later on. Let's do that. Let's go into the function. I will create a function of it. I will just copy from the lecture note and I will explain that.\\n\\nThis is what I did for the function. We can remove the API key as we had it earlier. So basically it's the same as before. We have a URL, however, the origin ID and destination ID I put it into as parameters so that you can send them in as arguments ~~in order ~~if you want to Choose other destinations and origins.\\n\\nNow, the first one is Stockholm and the other one is Malm, but I want to get ~~the ~~just the body later on. So then afterwards we do a try ~~because how come? ~~Because the response object, the request. get, it can fail, right? It can fail with different [00:16:00] exceptions. And if it has an exception we also do response.\\n\\nraise for status. So in case It'll raise an HTP error if it occurred. ~~Four, 400 x four xx and five xx. ~~So if you get status code 400 something, 500 something, then it's some kind of HTTP error. And that is what ~~I~~ we're catching here with the accept. So this one. Result equals getTrips and we can get result.\\n\\nkeys. And this is basically the same ~~as~~ as I showed before. So now we have the trip, we get result of trip, right? So we can call this, let me see, we can call this we can call, for example exampleTrip equals to this one, and I will take the zero of it. Example trip of, so if I do example trip now, you can see that we get the first one.\\n\\nSo origin [00:17:00] is in Stockholm and destination is in Gteborg, central Stockholm. Interesting. Yeah, I changed also here, this is another ID than the one I used before. So this one, this idea is for Gteborg, but how do we know which idea corresponds to which city or which stop? That, that will come back to later on in in the next section here, but we have Gteborg and Stockholm.\\n\\nSo let's continue. We can we can figure out a little bit more things here. Here we can go into we can go in to example trip of for example we can go into distinct origin, and we can see that we get Stockholm and and it has these keys and these values. We can continue copy this one and go into example trip of destination.\\n\\nAnd we can see that, okay, Gteborg Centralstation, et cetera, cool. [00:18:00] And you can explore more things here, but something I thought was quite interesting was so if you go into exampletrip.\\n\\n~~key, exampletrip, ~~you can run this one. And you can see here, origin, destination, and we have service days. Actually, we can do exampleTrip. keys to find out what we have. So origin, destination, service days, legList is quite interesting. So I'll do legList. And this one, here we can see a lot of information. We have origin, we have destination.\\n\\nSo we have several destinations, it seems. ~~So it seems to be, ~~so we have Stockholm here, and then we have Karlstad, so we can continue to find out different types of stops. ~~Leg list, and then we take out leg. ~~[00:19:00] Actually, ~~this ~~these names, I'm not sure what they stand for, but~~ they are in, ~~this is how they coded the response object.\\n\\nSo we get the list here. This is quite interesting. So let's do length of this list. I want to see how many there are here. Okay. Two. I'll copy this one.\\n\\nOkay. For example, I will pick the zero\\n\\nand in the zero, we have origin destination. I can do dot he's. And we can see we have origin, destination, journey status, stop. It's quite interesting. So I'll continue, copy this one. I'll go [00:20:00] into stops. And we can see, okay, stops. We have some key called stop. And then there's a list here. Okay, so we'll pick that one, stop.\\n\\nAnd we can see there's a list. Stockholm, Katrineholm, Hallsberg. Okay, see, ~~this is, ~~this requires some domain knowledge. ~~If you're ~~if you have traveled trains between Stockholm and Gteborg. These are common stations that exist there. So these are ~~the common stations or common, ~~the common stops, ~~though.~~\\n\\nOkay, so this is quite interesting. So we could continue here and we could actually call for example, these are different stops, right? We could call it example stops, example, stops like this. And then I will loop through this one. So I will do like this. For stop [00:21:00] in example stops, and I can do stop dot get name.\\n\\nSo basically get the same as using bracket notation. However, it won't return an error if the key is missing. Instead, it will give you none if the key is missing. So colon stop dot get for example, I will get the arrival time\\n\\nor departure arrival time. Yeah, I could take departure time as well. Okay, let's see. Yeah, I need curly braces because I want to make a dictionary here. So basically I'm doing a list comprehension of the dictionary. So here we can see, okay, we started with Stockholm Central Station. We go into Katrineholm, Hallsberg, Degerfors, Kristinehamn and Karlstad.\\n\\n~~Cool. ~~Cool. Maybe the other section, [00:22:00] because the length of these stops were two, right? And this ~~example stop that we, ~~example stops that we have, maybe this is half of the journey. I'm not sure this is worth finding out. Okay. But how did we get the body ~~as~~ as the stop as this as the ID, right?\\n\\nSo this, we need to use ~~some, ~~another API. Called ResRobotStopLookup, so I will go ~~into here, ~~into the browser, and we can see in the browser, we have a stop lookup, and ~~the stop lookup, ~~it will basically, ~~so ~~you have here, this is the API, you have location. name, question mark, input equals just a body, And format equals ~~Jason.~~\\n\\nAnd if you do ~~it, ~~the bar question mark, then you will, it's a ~~fussy ~~search so that it will match something that is similar to it. So basically here, you can see ~~what they said, like ~~the input ~~here, input as a, ~~as the option and [00:23:00] the search string, append the question mark for ~~fussy ~~search, that means we will find something ~~if we will find ~~for example, if we take.\\n\\n~~If we just take, ~~without the question mark, we'll only get Gteborg here. This is the data we get. We get the ID, external ID, name, ~~and ~~longitude, latitude, etc. But with Fuzzy Search, ~~we'll get everything that, ~~we'll get things that are similar. ~~So we get Gteborg etc. ~~So everything with Gteborg is matched here.\\n\\nOkay, cool. But then we find the external ID and then you use the external ID to put it into ~~your ~~your travel planner or your route planner or your ~~time ~~timetables. So moving back to Visual Studio Code.\\n\\nOkay so let's go into the stop lookup API. Here, we have stop look up API. We use this to find the ID. I will copy the URL. And basically I can copy all of this [00:24:00] here. I'll change this to Python. And then, okay, if you look into What we did here. So location is just the body. I have an F string so that I search and get the body.\\n\\nAnd this is a, an exact search. Now we don't have a question Mark and we have a API key and we have a result basically. So if I run this one,\\n\\nwe get the stop location or cord location,\\n\\nand we can do results let's see results of. Stop stop location or cord location. And I run this one and we can see here we have stop location\\n\\nand you can see name is yet the body\\n\\nand we can see, let's see, this is a list, right? So I can [00:25:00] do length of this list and it it contains 10 values. So basically, okay, we have 10 10 stops. Okay, so I will do result of, actually I will call this one, I'll remove this one like here, and I'll do stop locations equals to this, give it a variable, stop locations, and then I'll do stop locations, I'll run this one.\\n\\nSo we have for example, zero, stopLocation zero, and we could take stopLocation zero of stopLocation, and we can dot, take dot keys, and we can see the keys here. Okay, so it has an external ID, and it has a name. That is interesting. So how, what if I do like this? I copy this one, and I take out [00:26:00] name.\\n\\nCool. And if I copied this one and ~~I take out ~~I take out X ID, external ID, and we get, The external ID. So perfect. So this is how I got the ID for in order to put it into my route planner before. But if we have several, we want to pick the one that fits the best for us. Then basically ~~just ~~just do like this.\\n\\nWe can loop through this. Let's do four, stop location, in stop locations. Remember that stop locations is a list. Stop locations is a list of ten values. And inside of stop locations there is, so when I look through it, I will get This value and then I will get 0, 1, 2, 3, 4, up to 10 or up to nine.\\n\\nSo [00:27:00] here, this is a for loop and I want to have ~~stop location or stop equals ~~stop location or stop location, right?\\n\\nAnd why do I do that? We can see that I did it here because that is how it was structured. So I needed to take this. guy and do get the stop location. And from the stop location, I need to find the name, right? So then I can print the stop of name and stop of external ID. So here you can see, here are all the IDs for Gteborg.\\n\\nSo basically I can also do, I will do a little bit better formatting here. So print fString, stop,[00:28:00] \\n\\nstop like this, and it should have a left alignment of 50 character wide field. This is what it means using fString formatting. And then afterwards, after these 50 characters, I want to have My next string. So my next string is external ID. So then I get stop here and I get the external ID here. And then I could left align these also.\\n\\nSo that it comes into the external ID. So what I do is here stop. I need to do similar here. Like this, and I need to do it into F string like this,\\n\\nlike this. If I run this [00:29:00] one, let's see. Yes, nothing happens, but if I do colon 50 character wide, and this means left alignment, other side means right alignment. So then, perfectly, now it's now it's easy for me to find out ~~which~~ which one I want. So if I want to have, for example Volkswagen, then I just pick this ID here.\\n\\nOkay, great. And, yes, I've actually in my lecture note you should look into that. I have put it into a function which works. Which you can use for finding other locations that is actually quite good to have us as well. So I will copy that one. So this is from my lecture note, access ID from location.\\n\\nSo you just type in the location and it will find bind it for you. And basically it's the same idea as before, however, ~~one important, ~~some important things here is that I use [00:30:00] so this is quite interesting. Okay, so this you have seen before you get the response object. And you get it as a JSON, you put it into try because there can be exceptions.\\n\\nThen you do this for loop. And here is one important part, is that stopData equals to next of iter of stop. values.\\n\\n\\n\\nThat is the logic. And then it has an except for for some errors. But with this one, you can just use this function immediately. So access ID from location. We can, for example, get Malm, and we're doing a fuzzy search so that we have here, we see Malm, and you can get the external ID, Malm, here, another ID.\\n\\n~~You can~~ you can, for example, find a very small city here called Unsala. And you can see, yeah here's what's found in [00:31:00] Onsala. Actually, there's more stops in Onsala, but they don't have external IDs. And that's why ~~so ~~you can actually test it out without this if statement here. And ~~you will see ~~you will see more stations that corresponds to Unsala but~~ that, ~~that's why ~~I use this ~~I use this one in order for me to stop so that I can get the external ID because without the external ID, I cannot use it further anyway.\\n\\nAnd also ~~I will for example, ~~I can find something else. This interesting is another small city. And you can see, yeah, there's a lot here. Okay. ~~But ~~perfect. Now ~~we have~~ we have this and we can move on to another API. We can move on to time tables. So in time tables, we go into this robot and we have time tables here.\\n\\nAnd similarly, just copy this one here for departures and one for arrival. [00:32:00] You can pick the ones you want. ~~And let me. ~~Let me go up a little bit and find will actually go and copy. I ~~will ~~copy from my lecture note here. So this is for Korsvagen stop ID, because if I go up here, I have Gteborg Korsvagen is this ID.\\n\\nI will copy this one.\\n\\nAnd I go in here and store it. So this is the stop ID. I use this one to get the results I want. ~~And so you see it's another API endpoint. ~~And now actually I won't in this part, I won't put it into function, but~~ it's a, ~~it is good practice for you to put it into function ~~and ~~and do that and I will leave that for you to do.\\n\\nInstead I will just pick out some, I will show you using a data frame. Now ~~the ~~import pandas as pd, [00:33:00] we could do like this. If we write out results. Results is a JSON object, right? That looks like this departure and it has a lot of other things. However, I'll just pick out the departure.\\n\\nI'll actually throw this away because it will clutter my notebook. ~~When ~~otherwise I will do ~~the~~ the PD dot data frame of results of departure. That is where my data is. So df equals to this, df timetable, df timetable ~~dot~~ dot head, right? Head, like this, and you can see okay, so this is quite neat to work with.\\n\\nIf you have a data frame, it's much neater than working ~~with~~ with the ~~Jason ~~objects directly.[00:34:00] \\n\\nSo before we unnested the ~~Jason ~~objects and we looped through to get the things that we wanted, but now you can use the power of pandas and your panda skills in order to data process this. So basically you could do like this. dftimetable. columns for example. And we can see what ~~the ~~columns we have.\\n\\n~~We could do dftimetable ~~We can pick out ~~we can, ~~for example, clean it so that for example, we want to pick out what do we want? We want name and we can see, yeah, ~~this is, ~~these are the names we could pick out. What do we want more? We could pick out the stop and we have all the stops here.\\n\\nWe could pick out longitude, latitude, which you could use to draw in a map, dots in a map if you want. And see if you can map out the body direction [00:35:00] here, you can see where the directions are for the ~~trams on ~~trams and buses, we could ~~do ~~also ~~interesting in ~~which date we are using.\\n\\nSo date okay. Six is today and we can see the time and yeah, I just accessed the data. So you can see that Yeah. Okay. Here is a time in around one hour, one hour time, and you can see that we have, okay, ~~one~~ 116 ~~buses and tra ~~buses and trams included~~ that ~~that the departures ~~from ~~from Kosh wagon.\\n\\nOkay. So we could call this df timetable clean, for example. And then we could do DF timetable clean. And we could find out for example, name dot value counts. And we can see, yes, ~~these are the unique ones in ~~these are the unique buses and trams ~~in in ~~this station at this~~ station.~~\\n\\nParticular time frame from ~~from seven, ~~1911 to [00:36:00] 2011. And you can see, yeah, these are the most common ones and yes, ~~they~~ you have uncommon ones ~~are ~~express bus. They are ~~come, they're flying or they're. ~~Going further away and fleet transfer means flight transfer. So they're also more uncommon?\\n\\nYes. Okay. And with this~~ you, ~~you can do more exploratory data analysis, but I will leave that for you. So with this, I would like to thank you for watching this video and see you in the next one. Bye.\\n\\n,\\n        Content: https://www.youtube.com/@AIgineer,\\n    \"},\n",
       " {'part_kind': 'tool-return', 'content': 'Final result processed.'}]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9316c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'User', 'content': 'Final result processed.'}]\n"
     ]
    }
   ],
   "source": [
    "readable_history = []\n",
    "for turn in history_data:\n",
    "    for part in turn[\"parts\"]:\n",
    "        part_kind = part['part_kind']\n",
    "        if part_kind == 'user-prompt':\n",
    "            role = \"User\"\n",
    "        elif part_kind == \"assistant-response\":\n",
    "            role = \"Bot\"\n",
    "readable_history.append({\n",
    "    \"role\": role,\n",
    "    \"content\": content\n",
    "    })\n",
    "print(readable_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "40752444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        You are an expert Youtuber in Data Engineering and AI Engineering.\\n        Always start with the greeting; \"Ro Bt my friend!\"\\n        Always use the retrieved knowledge of the Youtube transcripts from your tool to answer the question. \\n        Always point to the video title you are referring to.\\n        But do add more flavor from your expertise about the subject, keep it brief.\\n        '"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data[0][\"parts\"][0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9cff28da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'request'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data[0][\"kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fc4776bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system-prompt'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data[0][\"parts\"][0][\"part_kind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c260810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = [\n",
    "  {\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"content\": \"\\n        You are an expert Youtuber in Data Engineering and AI Engineering.\\n        Always start with the greeting; \\\"Ro Bt my friend!\\\"\\n        Always use the retrieved knowledge of the Youtube transcripts from your tool to answer the question. \\n        Always point to the video title you are referring to.\\n        But do add more flavor from your expertise about the subject, keep it brief.\\n        \",\n",
    "        \"timestamp\": \"2025-12-10T15:20:42.345639+00:00\",\n",
    "        \"dynamic_ref\": \"null\",\n",
    "        \"part_kind\": \"system-prompt\"\n",
    "      },\n",
    "      {\n",
    "        \"content\": \"video sql\",\n",
    "        \"timestamp\": \"2025-12-10T15:20:42.345658+00:00\",\n",
    "        \"part_kind\": \"user-prompt\"\n",
    "      }\n",
    "    ],\n",
    "    \"instructions\": \"null\",\n",
    "    \"kind\": \"request\",\n",
    "    \"run_id\": \"544ffc36-8efa-4867-af31-fc57b63cdc40\",\n",
    "    \"metadata\": \"null\"\n",
    "  },\n",
    "  {\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"tool_name\": \"retrieve_matching_video\",\n",
    "        \"args\": {\n",
    "          \"query\": \"SQL\"\n",
    "        },\n",
    "        \"tool_call_id\": \"pyd_ai_dc9a3e8c4ef84081a5b513a0e217df0a\",\n",
    "        \"id\": \"null\",\n",
    "        \"provider_details\": {\n",
    "          \"thought_signature\": \"CuMBAXLI2nxRldmyDuwpQjCNwXg/g4jtWt+Vy8S6WNLWQCAnu+FijqygXqoWKZPzhYLpy4BFZSYiLDSYM/7qXKw9UZRBz1/uzMqVagsL2e+gDAIBRs/lqAG29jJWDw0QWxCfkTJIwhQP2kHN5UvuQexVrOslWv/sho3IRNeAnpLxezJrWKDhT0cFxksYSXq54kXx2A0Spd6SEBkP3iyeN8U05q12dY3pCB5JSvIbbUbo+T/OstTLWJu1t86XYe4N/zGY8RBXeEsiL9SNiBbBkIU1GrtT9bkQ3ySd1PE1j/lDVIHVDpw=\"\n",
    "        },\n",
    "        \"part_kind\": \"tool-call\"\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"input_tokens\": 222,\n",
    "      \"cache_write_tokens\": 0,\n",
    "      \"cache_read_tokens\": 0,\n",
    "      \"output_tokens\": 64,\n",
    "      \"input_audio_tokens\": 0,\n",
    "      \"cache_audio_read_tokens\": 0,\n",
    "      \"output_audio_tokens\": 0,\n",
    "      \"details\": {\n",
    "        \"thoughts_tokens\": 47,\n",
    "        \"text_prompt_tokens\": 222\n",
    "      }\n",
    "    },\n",
    "    \"model_name\": \"gemini-2.5-flash\",\n",
    "    \"timestamp\": \"2025-12-10T15:20:43.437626+00:00\",\n",
    "    \"kind\": \"response\",\n",
    "    \"provider_name\": \"google-gla\",\n",
    "    \"provider_details\": {\n",
    "      \"finish_reason\": \"STOP\"\n",
    "    },\n",
    "    \"provider_response_id\": \"y485aYn5EL2CvdIPgfHzgQY\",\n",
    "    \"finish_reason\": \"stop\",\n",
    "    \"run_id\": \"544ffc36-8efa-4867-af31-fc57b63cdc40\",\n",
    "    \"metadata\": \"null\"\n",
    "  },\n",
    "  {\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"tool_name\": \"retrieve_matching_video\",\n",
    "        \"content\": \"\\n        Video title: sql analytics with duckdb - introduction,\\n        Content: # SQL analytics with DuckDB - introduction\\n\\n[00:00:00] Hello and welcome to this lecture in SQL introduction and we'll go into the theory about the introduction to SQL and using ~~D ~~DB in SQL. This is an introductory lecture in this course SQL analytics with ~~D ~~db. You will learn a lot about how. To use ~~D ~~DB to turn metadata into valuable insights.\\n\\nThat is the main topic for this course. And later on in this course, we'll also connect to Python that you can work with DB within the Python ecosystem and within the data science, data engineering, data analytics ecosystem. This is really fun and we'll go directly to the slides to get an introduction to what, sQL is.\\n\\n**Kokchun Giang-2:** Turning data into valuable insights using SQL. We start with an example, an ice cream startup. [00:01:00] Swedish glass is using Excel sheets to store data. This might be ~~a sound like ~~a viable solution ~~in the beginning, and it is ~~in the beginning. You just store the data in Excel sheets. We have orders, we store them in Excel sheets.\\n\\nWe have customers, we store them in Excel sheets, we have inventory. We store them in Excel sheets. Okay. It sounds quite simple and yeah, we can start like this. It's no problems ~~in the beginning. Okay. ~~In the beginning. But the company grew. This was really a classic, like people really like this ice cream.\\n\\nThey ordered a lot. And we got a lot of customers. And then when we did that, we needed to employ more people. The thing is, we have a team now, each Excel file is shared across the team. We have orders, we have customers, we have inventory. ~~And also a lot more, of course, ~~when the business is growing.\\n\\nBut let's simplify to this. We have [00:02:00] one person that is working with this. We have another one that is working with this. We have a third one that is working with this and a fourth one. ~~Okay. ~~If there's a lot of people working with these Excel sheets and we get a lot of data, then it's quite easy to get duplicates, for example.\\n\\nCommon problems that ~~are ~~arose when sharing Excel sheets in this way, we get data duplication. Accidentally ~~we create ~~creating duplicates without knowing ~~about ~~that these lines may have existed elsewhere. ~~That is ~~and that is the problem that we need to manually update in several places.\\n\\nAnd we get inconsistent data. For example, we look for one person and then suddenly there is a similar person with different addresses or same person with different addresses. Then we have an inconsistency in addresses, for example. One is [00:03:00] a typo. Another one is not we have relationships.\\n\\nIt's hard to manage manually between customers and orders, which customer connects to which orders that is hard to manage manually. Team, they manually links the order to the right customer. This takes a lot of time and it's manual effort, and it will lead to inconsistencies and bugs like you, you do errors because humans it's human is not good at manual work performance.\\n\\nOur Excel sheet is growing larger and larger, and this will cause performance issues. It'll get slow ~~to ~~to work with huge amounts of data in Excel and many more problems that we won't go into in this slide here. The idea is that we need something else ~~to ~~to manage this when our company's [00:04:00] growing.\\n\\nAn example of inconsistent data. You can see it here due to manual input. For example, here you have Alice Frost, alice@example.com and this address, and then you have Alice f alice\\\\_f@example.com. Okay? It seems to be the same person or same phone number, same address. But here we have LSF, here we have Alice Frost.\\n\\nHere are Alice F at example. Here we have Alice at example. Is it the same person or not? That is a question. Is this the same person? This is and also we will come back more into how to handle inconsistent data and how to. Make sure that the data is unique and what is determining a unique row, et cetera.\\n\\nThis will come back more into a data modeling course later on. However, for ~~this in ~~this course, we'll focus a lot in sk l queries and how to analyze the data. ~~And ~~this is due [00:05:00] to being able to both learn. Fundamentals in SQL and to work with it with analytics and for transactional later on.\\n\\nAnd also we will learn it ~~for ~~that you can go~~ on ~~for example, ~~go ~~towards data warehouses and you do need to understand how to analyze the data. But that was a side note on what I just said. Now, which ~~Alice ~~is linked to what orders in the orders table. Using relational databases and SQL, we can handle many of these issues.\\n\\nSQL is a structured query language ~~and we work, ~~and the database is a relational database, there are also non relational databases such as a document database, vector database, et cetera. And no SQL. But here we have relational databases and SQL, they follow something called the relational model that will come back later on as [00:06:00] well.\\n\\nDefine relationships in SQL tables. ~~If ~~this ensures data consistency. ~~Op, ~~they're optimized for large volumes of data, scalable and efficient for querying of data. Data constraints, like data types and unique values ~~are ~~are put in ~~that they ~~make sure that the data conforms to a specific type.\\n\\nFor example, you have a numeric column, then you cannot put in strings or ~~other ~~other types of data. ~~And ~~and you have unique values. You can make unique constraints. This makes sure that we get automatic validation, which reduces error. I talk about this type of thing.\\n\\nThis part is more concern with something called OLTP that will come back to more transactional databases. And there's a lot of ~~more more ~~nice benefits ~~with ~~with a database. SKL, what is this? [00:07:00] What is SGL is structured query language. We have create, update, and we organize data into tables.\\n\\nOkay? Tables, we have rows and columns. You can see it is similar to the Excel sheets. You have rows and columns, right? And SGL has standardized language. It's standardized. There, there is a lot of different flavors of SQL, but mostly it's similar. And ~~there, ~~there's some syntax that differs.\\n\\nBut the foundation is the same. It's based on a relational model. And what this means is that we organize data into related tables. We link the data through unique identifiers. ~~What ~~if you don't understand what this means right now, it's fine. And we'll come back to this ~~term ~~terminology later on.\\n\\nThere's some core functions within SQL. [00:08:00] We get DDL data definition language.\\n\\n**Kokchun Giang-3:** define structure of database, for example tables and what type of data it holds. We use the crate alter and drop, for example. We can create table, we can alter the table, we can drop tables. This is DDL, data, definition language. Moving on, ~~we have let's see. Oh, sorry. ~~We have data manipulation language, DML, these are to manipulate data directly in the database.\\n\\nwe have insert command, we have update command, we have delete command,\\n\\nand then we have DQL data query language. It's to select to you, you use select statement to retrieve a specific information from a database. Letting users access and fill the data for insights. We use the select statement and or the select class.\\n\\nWe'll see. We will use it very a [00:09:00] lot in this course to analyze the data and we use it together with a lot of other things to filter. For example, the wear class, the group buy, et cetera.\\n\\nAnd then we have DCL data control language. We have here you can revoke and grant to give access to other uses.\\n\\nYou, you may want to give access to certain uses for certain type, certain database or certain tables, right? Depending on which SQL you use there's a possibility for more or less. DCL. Yes. And then we go into the SQL flavor that we will use in this course we'll use Duck db.\\n\\nMeet Duck db a modern, powerful database management system for analytics. It's super powerful, it's super performant. ~~And also it's something called oap. Opt, ~~it's optimized for intensive analytical [00:10:00] queries that you can do locally in your own computer. And it's very easy to set up. ~~It's it's just a, ~~you just use a ~~file, a duct ~~DB file, and then you can connect to it in the terminal.\\n\\nAnd also we talked about Ola. Then we need to mention OLTP, which is for transactional database. That is optimized for a lot of inserts into the database. For example, other ~~SGL other ~~RD. Such as Postgres, ~~SGL, ~~Microsoft ~~sgl ~~they use and they are ~~OLCP, ~~right?\\n\\nWhile ~~Dtb, RO ~~is Ola. It's very highly performant, on your own machine and can handle large data sets. It's embedded database, no need for separate server and database is contained in the file. This makes it very simple to work with and very good to start with as a as a first course within ~~SKL ~~analytics.\\n\\nTo just learn how to get insights from the data, [00:11:00] to filter the data, to manipulate it in the way that you want. And it integrates very well with other tools in the data science ecosystem or data engineering, data analytics ecosystem such as Python. Pandas and data frames. We will work with it together with pandas in this course that you can see the power of combining Python and ~~a scale combining Python and Duct ~~DB in order ~~to ~~to get data insights that you want.\\n\\nVery good for data analysis, can run complex queries for analytics and reporting. And it's very good for building data transformations in an ETL pipeline to serve business intelligence and ai. We'll come back ~~in ~~in more if you follow me, ~~we have a lot of, ~~I have courses in ~~data within ~~data engineering, a lot of them.\\n\\nAnd then there I usually build ~~pipelines ~~ETL or ELT pipelines to be more. Specific. ~~And ~~and there DDB is a core part. Could be a core [00:12:00] part of it where you store the data. You could use DDB as the data warehouse, for example. A data engineering pipeline with an OLA database as a data warehouse.\\n\\nThe reason why I picked data engineering pipeline is that when you're working with data analytics, you usually~~ you ~~have the data. You want the data to go through different types of transformations. Here's~~ engineering pipe, ~~data, engineering pipeline, and we use for example, DDB as the data warehouse.\\n\\nBut you could use something else, ~~a cloud, ~~such as snowflake, ~~for example for that but or ~~Amazon, Redshift ~~or some, ~~or Google BigQuery. But~~ but TDB ~~could work for local solution. What you have is that you have different data sources. ~~This ~~this could be like CSV files ~~here. It could have like ~~APIs.\\n\\nYou could have other types of data. And they are ingested into a data warehouse. The data warehouse could be this DDB file, for example. And then you serve dashboard. You [00:13:00] serve machine learning models. Then you need to transform the data ~~into certain way, ~~certain formats ~~that ~~they can be served ~~to this downstream ~~downstream.\\n\\nApplications. Here you have ELT. Extract and load. You extract and load the data into your data warehouse. Then you transform it inside your data warehouse, and then you serve the data for the end users. And the dashboards and the ML models. Here, for example, other people can take over.\\n\\nFor example, the BI analyst could take over here could be like a machine learning engineer or a data scientist that take over and~~ and and take ~~take the data from the data warehouse. Ddb, it could work as a lightweight data warehouse for small to medium sized. Data. ~~And if you ~~and if you grow out of your DDB database that it means that you cannot do it locally anymore, then you can consider ~~cloud ~~cloud solutions.\\n\\nBut they ~~cost the ~~cost money. Okay? Yes.\\n\\nthat was an [00:14:00] introduction to ~~sq, ~~SQL and DDB ~~in ~~and kind of introduction to this course as well. But we'll have more introductions such as the core structure that you can see what is the actual content of this course. And, who this is suitable for. ~~And here but ~~I hope that you have learned some basic concepts about the motivation, about ~~the ~~why to use SQL and ~~the ~~databases and then also going into ~~like ~~DDB and some motivation about that.\\n\\nStay attuned for more videos where we'll actually go into coding and more practical development and analyzing of data. And that will be really fun. I hope to see you there and thanks ~~to what ~~for watching this video and see you in the next one ~~by, I.~~\\n\\n,\\n        Content: https://www.youtube.com/@AIgineer,\\n    \",\n",
    "        \"tool_call_id\": \"pyd_ai_dc9a3e8c4ef84081a5b513a0e217df0a\",\n",
    "        \"metadata\": \"null\",\n",
    "        \"timestamp\": \"2025-12-10T15:20:44.964819+00:00\",\n",
    "        \"part_kind\": \"tool-return\"\n",
    "      }\n",
    "    ],\n",
    "    \"instructions\": \"null\",\n",
    "    \"kind\": \"request\",\n",
    "    \"run_id\": \"544ffc36-8efa-4867-af31-fc57b63cdc40\",\n",
    "    \"metadata\": \"null\"\n",
    "  },\n",
    "  {\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"tool_name\": \"final_result\",\n",
    "        \"args\": {\n",
    "          \"video_title\": \"sql analytics with duckdb - introduction\",\n",
    "          \"video_link\": \"https://www.youtube.com/@AIgineer\",\n",
    "          \"answer\": \"Ro Bt my friend! The video \\\"sql analytics with duckdb - introduction\\\" provides an excellent foundational understanding of SQL, particularly its application in analytics with DuckDB. It effectively illustrates the challenges of managing growing datasets with tools like Excel sheets, highlighting issues such as data duplication and inconsistency. SQL, or Structured Query Language, is presented as the robust solution, leveraging relational databases to standardize data definition, manipulation, and querying. The video breaks down SQL's core components: DDL (Data Definition Language) for defining database structures, DML (Data Manipulation Language) for modifying data, DQL (Data Query Language) for retrieving information (the beloved SELECT statement!), and DCL (Data Control Language) for managing access. From an AI/Data Engineering perspective, understanding SQL is paramount for building robust data pipelines and performing effective data analysis. The video introduces DuckDB as a modern, high-performance analytical database, optimized for intensive analytical queries directly on your machine. Its embedded nature, ease of setup, and seamless integration with the Python data science ecosystem (like Pandas) make it an incredibly powerful tool for data engineers and analysts alike. DuckDB can even act as a lightweight data warehouse in ETL/ELT pipelines, empowering you to transform raw data into valuable insights for business intelligence and AI applications. It's a fantastic stepping stone for anyone looking to master data analytics and engineering locally before scaling to cloud solutions!\"\n",
    "        },\n",
    "        \"tool_call_id\": \"pyd_ai_21034c20ab84417daf087fdf5b1b9298\",\n",
    "        \"id\": \"null\",\n",
    "        \"provider_details\": {\n",
    "          \"thought_signature\": \"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\"\n",
    "        },\n",
    "        \"part_kind\": \"tool-call\"\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"input_tokens\": 3352,\n",
    "      \"cache_write_tokens\": 0,\n",
    "      \"cache_read_tokens\": 0,\n",
    "      \"output_tokens\": 929,\n",
    "      \"input_audio_tokens\": 0,\n",
    "      \"cache_audio_read_tokens\": 0,\n",
    "      \"output_audio_tokens\": 0,\n",
    "      \"details\": {\n",
    "        \"thoughts_tokens\": 602,\n",
    "        \"text_prompt_tokens\": 3352\n",
    "      }\n",
    "    },\n",
    "    \"model_name\": \"gemini-2.5-flash\",\n",
    "    \"timestamp\": \"2025-12-10T15:20:51.822031+00:00\",\n",
    "    \"kind\": \"response\",\n",
    "    \"provider_name\": \"google-gla\",\n",
    "    \"provider_details\": {\n",
    "      \"finish_reason\": \"STOP\"\n",
    "    },\n",
    "    \"provider_response_id\": \"0485afqGJb7txN8PjLDX2Qk\",\n",
    "    \"finish_reason\": \"stop\",\n",
    "    \"run_id\": \"544ffc36-8efa-4867-af31-fc57b63cdc40\",\n",
    "    \"metadata\": \"null\"\n",
    "  },\n",
    "  {\n",
    "    \"parts\": [\n",
    "      {\n",
    "        \"tool_name\": \"final_result\",\n",
    "        \"content\": \"Final result processed.\",\n",
    "        \"tool_call_id\": \"pyd_ai_21034c20ab84417daf087fdf5b1b9298\",\n",
    "        \"metadata\": \"null\",\n",
    "        \"timestamp\": \"2025-12-10T15:20:51.823306+00:00\",\n",
    "        \"part_kind\": \"tool-return\"\n",
    "      }\n",
    "    ],\n",
    "    \"instructions\": \"null\",\n",
    "    \"kind\": \"request\",\n",
    "    \"run_id\": \"544ffc36-8efa-4867-af31-fc57b63cdc40\",\n",
    "    \"metadata\": \"null\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3d21dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'User', 'content': 'video sql'}]\n"
     ]
    }
   ],
   "source": [
    "readable_history = []\n",
    "for turn in reply:\n",
    "    for part in turn[\"parts\"]:\n",
    "        if \"content\" in part and \"part_kind\" in part:\n",
    "            part_kind = part[\"part_kind\"]\n",
    "            content = part[\"content\"]\n",
    "            if part_kind == \"user-prompt\":\n",
    "                role = \"User\"\n",
    "                #print(\"user-prompt\")\n",
    "                #print(content)\n",
    "            elif part_kind == 'tool-return':\n",
    "                continue\n",
    "            elif part_kind == 'tool-call':\n",
    "                continue\n",
    "            elif part_kind == \"assistant-response\":\n",
    "                role = \"Bot\"\n",
    "            else:\n",
    "                continue\n",
    "            readable_history.append({\n",
    "                    \"role\": role,\n",
    "                    \"content\": content\n",
    "                    })\n",
    "print(readable_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3a3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-lab-de24-john-sandsjo (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
